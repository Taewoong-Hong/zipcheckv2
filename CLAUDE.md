# ğŸ§© **ì§‘ì²´í¬ (ZipCheck) LLM ë¦¬íŒ©í† ë§ PRD v2 + êµ¬í˜„ êµ¬ì¡°**

## ğŸ¨ ë¸Œëœë“œ ì»¬ëŸ¬
- **Primary Colors**:
  - Red/Pink ê³„ì—´ì˜ ê·¸ë¼ë°ì´ì…˜ (ë©”ì¸ ë¡œê³  ì»¬ëŸ¬)
  - #D32F2F (ì§„í•œ ë¹¨ê°•)
  - #E91E63 (í•‘í¬)
  - #FF5252 (ë°ì€ ë¹¨ê°•)

---

## ğŸ§± ê¶Œì¥ êµ¬ì¡° (í•˜ì´ë¸Œë¦¬ë“œ)
```
zipcheck-v2/
â”œâ”€ apps/web/                 # Next.js 15 (TS) - UI/ê²°ì œ/ì¸ì¦
â”œâ”€ services/ai/              # â¬… Python FastAPI - LLM/RAG/íŒŒì‹±
â”‚  â”œâ”€ app.py
â”‚  â”œâ”€ core/
â”‚  â”‚  â”œâ”€ chains.py
â”‚  â”‚  â”œâ”€ embeddings.py
â”‚  â”‚  â”œâ”€ retriever.py
â”‚  â”‚  â””â”€ risk_rules.py
â”‚  â”œâ”€ ingest/
â”‚  â”‚  â”œâ”€ pdf_parse.py
â”‚  â”‚  â””â”€ upsert_vector.py
â”‚  â”œâ”€ eval/                  # RAG í’ˆì§ˆí‰ê°€(ragas ë“±)
â”‚  â””â”€ requirements.txt
â””â”€ db/                       # Supabase ìŠ¤í‚¤ë§ˆ/RLS/sql
```

---

## ğŸ Python íŒ¨í‚¤ì§€ (services/ai/requirements.txt)
```
fastapi[all]
uvicorn[standard]
langchain
langchain-community
langchain-openai
pydantic
python-dotenv
psycopg[binary]==3.1.19      # â­ psycopg3 ì‚¬ìš© (psycopg2 ëŒ€ì‹ )
SQLAlchemy
pgvector
sentence-transformers
unstructured[pdf]
pymupdf
tiktoken
tenacity
ragas
```

---

## âš™ï¸ ìµœì†Œ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸

### 1ï¸âƒ£ ì„ë² ë”© & ë²¡í„°DB (Postgres + pgvector)
```python
# services/ai/core/embeddings.py
from langchain_openai import OpenAIEmbeddings

def get_embedder():
    # ëª¨ë¸ì€ ìƒí™©ì— ë§ê²Œ êµì²´ ê°€ëŠ¥ (OpenAI, nomic, bge ë“±)
    return OpenAIEmbeddings(model="text-embedding-3-large")
```

```python
# services/ai/core/retriever.py
from langchain_community.vectorstores.pgvector import PGVector
from sqlalchemy import create_engine
from .embeddings import get_embedder
import os

def get_pg_connection():
    url = os.environ["DATABASE_URL"]  # Supabase Postgres URL
    # â­ psycopg3ë¥¼ ìœ„í•œ URL ìŠ¤í‚´ ë³€ê²½
    if url.startswith("postgresql://"):
        url = url.replace("postgresql://", "postgresql+psycopg://", 1)
    return create_engine(
        url,
        pool_pre_ping=True,
        pool_size=5,
        max_overflow=5,
        connect_args={"prepare_threshold": 0}  # Supabase pooler í˜¸í™˜ì„±
    )

def get_vectorstore():
    engine = get_pg_connection()
    collection = "v2_contract_docs"
    return PGVector(
        connection=engine,
        collection_name=collection,
        embedding_function=get_embedder(),
    )

def get_retriever(k: int = 6):
    vs = get_vectorstore()
    return vs.as_retriever(search_kwargs={"k": k})
```

---

### 2ï¸âƒ£ ê³„ì•½ì„œ íŒŒì‹± â†’ ì²­í¬ â†’ ì—…ì„œíŠ¸
```python
# services/ai/ingest/pdf_parse.py
from unstructured.partition.pdf import partition_pdf

def parse_pdf_to_text(path: str) -> str:
    elements = partition_pdf(filename=path, strategy="fast")
    return "\n".join([e.text for e in elements if hasattr(e, "text") and e.text])
```

```python
# services/ai/ingest/upsert_vector.py
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from ..core.retriever import get_vectorstore

def upsert_contract_text(doc_id: str, text: str, metadata: dict):
    splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=150)
    chunks = splitter.split_text(text)
    docs = [Document(page_content=c, metadata={**metadata, "doc_id": doc_id}) for c in chunks]
    vs = get_vectorstore()
    vs.add_documents(docs)
```

---

### 3ï¸âƒ£ ì²´ì¸(LCEL) + ê·¼ê±° ìŠ¤ë‹ˆí« ì¸ìš©
```python
# services/ai/core/chains.py
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from .retriever import get_retriever

def build_contract_analysis_chain():
    retriever = get_retriever(k=6)
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)

    prompt = ChatPromptTemplate.from_template(
        """ë„ˆëŠ” ë¶€ë™ì‚° ê³„ì•½ ë¦¬ìŠ¤í¬ ì ê²€ ë³´ì¡°ì›ì´ë‹¤.
ì‚¬ìš©ì ì§ˆë¬¸: {question}

ë‹¤ìŒì€ ê²€ìƒ‰ëœ ê·¼ê±° ìŠ¤ë‹ˆí«ë“¤ì´ë‹¤:
{context}

ìš”êµ¬ì‚¬í•­:
- ê³„ì•½ ë¦¬ìŠ¤í¬ë¥¼ ì¡°ëª©ì¡°ëª© ë¦¬ìŠ¤íŠ¸ë¡œ ì •ë¦¬
- ê° í•­ëª©ë§ˆë‹¤ 'ê·¼ê±° ìŠ¤ë‹ˆí« ìš”ì•½'ê³¼ 'ê¶Œì¥ ì¡°ì¹˜' í¬í•¨
- ë²•ë¥  ë‹¨ì • í‘œí˜„ì€ ì§€ì–‘í•˜ê³ , ì°¸ê³ /ê²€í† /ì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œì¥
"""
    )

    # LCEL íŒŒì´í”„ë¼ì¸
    def _retrieve(inputs):
        docs = retriever.get_relevant_documents(inputs["question"])
        ctx = "\n\n---\n\n".join([d.page_content[:800] for d in docs])
        return {"context": ctx, **inputs}

    chain = _retrieve | prompt | llm
    return chain
```

---

### 4ï¸âƒ£ FastAPI ì—”ë“œí¬ì¸íŠ¸
```python
# services/ai/app.py
import os
from fastapi import FastAPI, UploadFile, Form
from pydantic import BaseModel
from ingest.pdf_parse import parse_pdf_to_text
from ingest.upsert_vector import upsert_contract_text
from core.chains import build_contract_analysis_chain

app = FastAPI(title="ZipCheck AI")

class AskBody(BaseModel):
    question: str

@app.post("/ingest")
async def ingest(file: UploadFile, contract_id: str = Form(...), addr: str = Form("")):
    # 1) íŒŒì¼ ì €ì¥
    path = f"/tmp/{contract_id}.pdf"
    with open(path, "wb") as f:
        f.write(await file.read())
    # 2) íŒŒì‹± -> ì—…ì„œíŠ¸
    text = parse_pdf_to_text(path)
    upsert_contract_text(contract_id, text, {"addr": addr})
    return {"ok": True, "contract_id": contract_id, "length": len(text)}

@app.post("/analyze")
async def analyze(body: AskBody):
    chain = build_contract_analysis_chain()
    resp = chain.invoke({"question": body.question})
    return {"answer": resp.content}
```

> Next.jsì—ì„œ `/api/contract/analyze`ëŠ” ìœ„ FastAPIë¡œ í”„ë¡ì‹œ í˜¸ì¶œ.
> ì¥ì‹œê°„ ì‘ì—…(ëŒ€ìš©ëŸ‰ PDF)ì€ í(Celery/RQ)ë¡œ ë¹„ë™ê¸° ì²˜ë¦¬ í›„ ì›¹í›…/í´ë§.

---

## ğŸš€ Google Cloud Run ë°°í¬ (2025-01-20 ì™„ë£Œ)

### âœ… ì™„ë£Œëœ ì‘ì—…
1. **GCP í”„ë¡œì íŠ¸ ì„¤ì •**
   - í”„ë¡œì íŠ¸ ID: `advance-vector-475706-a5`
   - í”„ë¡œì íŠ¸ ì´ë¦„: `zipcheck123`
   - ë¦¬ì „: `asia-northeast3` (ì„œìš¸)

2. **API í™œì„±í™”**
   - Cloud Run API
   - Cloud Build API
   - Secret Manager API

3. **Secret Manager ì„¤ì •**
   - `openai-api-key`: OpenAI API í‚¤ ì €ì¥
   - `supabase-database-url`: Supabase Postgres ì—°ê²° URL ì €ì¥

4. **Service Account ìƒì„±**
   - ì´ë¦„: `zipcheck-ai-sa`
   - ê¶Œí•œ: Secret Manager ì ‘ê·¼ ê¶Œí•œ ë¶€ì—¬

5. **ì˜ì¡´ì„± í˜¸í™˜ì„± í•´ê²°**
   - `psycopg2-binary` â†’ `psycopg[binary]==3.1.19` ì—…ê·¸ë ˆì´ë“œ
   - `core/database.py`ì—ì„œ URL ìŠ¤í‚´ ë³€ê²½ (`postgresql://` â†’ `postgresql+psycopg://`)
   - Supabase pooler í˜¸í™˜ì„± ì„¤ì • ì¶”ê°€ (`prepare_threshold=0`)

6. **ë¹Œë“œ ì„¤ì •**
   - `.python-version` íŒŒì¼ ìƒì„± (Python 3.11.9 ì§€ì •)
   - `Procfile` ìƒì„± (ì†ŒìŠ¤ ê¸°ë°˜ ë°°í¬ìš©)
   - `.gcloudignore` ì—…ë°ì´íŠ¸

### ğŸ”§ ë°°í¬ ëª…ë ¹ì–´
```bash
cd C:\dev\zipcheckv2

gcloud run deploy zipcheck-ai \
  --source services/ai \
  --region asia-northeast3 \
  --allow-unauthenticated \
  --set-env-vars "APP_ENV=production,LOG_LEVEL=INFO" \
  --set-secrets "OPENAI_API_KEY=openai-api-key:latest,DATABASE_URL=supabase-database-url:latest"
```

### âš ï¸ ë°°í¬ ì¤‘ í•´ê²°í•œ ì´ìŠˆ
1. **Python ë²„ì „ ë¬¸ì œ**
   - ì´ˆê¸°: Buildpackì´ Python 3.13.9ë¥¼ ìë™ ì„ íƒ
   - í•´ê²°: `.python-version` íŒŒì¼ë¡œ Python 3.11.9 ê³ ì •

2. **psycopg2 í˜¸í™˜ì„± ë¬¸ì œ**
   - ì´ˆê¸°: `psycopg2-binary==2.9.9`ê°€ Python 3.13ê³¼ í˜¸í™˜ ì•ˆ ë¨
   - í•´ê²°: `psycopg[binary]==3.1.19`ë¡œ ì—…ê·¸ë ˆì´ë“œ + URL ìŠ¤í‚´ ë³€ê²½

3. **pymupdf ë¹Œë“œ ë¬¸ì œ**
   - ë¬¸ì œ: Python 3.13ì—ì„œ ì†ŒìŠ¤ ë¹Œë“œ ì‹œë„í•˜ì—¬ 10ë¶„+ ì†Œìš”
   - í•´ê²°: Python 3.11ë¡œ ê³ ì •í•˜ì—¬ prebuilt wheel ì‚¬ìš©

### ğŸ“ ìƒì„±ëœ íŒŒì¼
- `services/ai/.python-version`: Python ë²„ì „ ê³ ì •
- `services/ai/Procfile`: Cloud Run ì‹œì‘ ëª…ë ¹ì–´
- `services/ai/runtime.txt`: Python ë²„ì „ ì§€ì • (ë°±ì—…ìš©)
- `services/ai/DEPLOY_SOURCE.md`: ì†ŒìŠ¤ ê¸°ë°˜ ë°°í¬ ê°€ì´ë“œ

---

## ğŸ“‹ í–¥í›„ ì‘ì—… (Next Steps)

### 1ï¸âƒ£ Cloud Run ë°°í¬ ì™„ë£Œ (ì§„í–‰ ì¤‘)
- [ ] `.python-version` íŒŒì¼ë¡œ Python 3.11.9 ë¹Œë“œ í™•ì¸
- [ ] ë°°í¬ ì„±ê³µ ë° ì„œë¹„ìŠ¤ URL í™•ì¸
- [ ] Health check ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
- [ ] API ë¬¸ì„œ (`/docs`) í™•ì¸

### 2ï¸âƒ£ ë°°í¬ í›„ ê²€ì¦
- [ ] `/healthz` ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
- [ ] `/analyze` API í˜¸ì¶œ í…ŒìŠ¤íŠ¸
- [ ] OpenAI API ì—°ë™ í™•ì¸
- [ ] Supabase ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
- [ ] ë¡œê·¸ í™•ì¸ (Cloud Logging)
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •

### 3ï¸âƒ£ Next.js í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™
- [ ] Next.js API Routeì—ì„œ Cloud Run URLë¡œ í”„ë¡ì‹œ ì„¤ì •
- [ ] í™˜ê²½ë³€ìˆ˜ì— Cloud Run URL ì¶”ê°€
- [ ] CORS ì„¤ì • í™•ì¸
- [ ] í”„ë¡ íŠ¸ì—”ë“œì—ì„œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸

### 4ï¸âƒ£ ì¶”ê°€ ê¸°ëŠ¥ êµ¬í˜„
- [ ] PDF ì—…ë¡œë“œ ë° íŒŒì‹± í…ŒìŠ¤íŠ¸
- [ ] ë²¡í„° ì„ë² ë”© ë° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
- [ ] RAG í’ˆì§ˆ í‰ê°€ (ragas)
- [ ] ë¹„ìš© ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
- [ ] Rate limiting ì„¤ì •
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”

### 5ï¸âƒ£ í”„ë¡œë•ì…˜ ì¤€ë¹„
- [ ] CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- [ ] ë¡œê·¸ ì§‘ê³„ ë° ëª¨ë‹ˆí„°ë§ (Sentry, Langfuse)
- [ ] ë°±ì—… ë° ì¬í•´ ë³µêµ¬ ê³„íš
- [ ] ë³´ì•ˆ ê²€í†  (Secret rotation, RLS ì •ì±…)
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ ìµœì í™”
- [ ] ë¬¸ì„œí™” ë° ìš´ì˜ ê°€ì´ë“œ ì‘ì„±

---

## ğŸ§© ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
- **RLS**: `v2_documents`, `v2_embeddings`ì— ì‚¬ìš©ì/í…Œë„ŒíŠ¸ ë‹¨ìœ„ ì •ì±… í•„ìˆ˜
- **ì¶œì²˜ í‘œê¸°**: ì‘ë‹µì— ì„ íƒëœ ë¬¸ë‹¨ì˜ `doc_id / page/offset`ì„ í•¨ê»˜ ë°˜í™˜
- **ê°€ë“œë ˆì¼**: ìœ„í—˜ ë¬¸ì¥ ì°¨ë‹¨("ë²•ë¥ ì  í™•ì •" ë“±), ë¹„ìš© ìƒí•œ, ì¬ì‹œë„/ë°±ì˜¤í”„(tenacity)
- **ë¡œê·¸/í‰ê°€**: Langfuse + ragasë¡œ ì¿¼ë¦¬/ì •í™•ë„/ë¼ë²¨ ê´€ë¦¬
- **ë°°í¬**: Cloud Run ì†ŒìŠ¤ ê¸°ë°˜ ë°°í¬ (Buildpacks)
- **ëª¨ë‹ˆí„°ë§**: Cloud Logging, Error Reporting, Cloud Monitoring ì„¤ì •

---

## ğŸ’¡ í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒ
- **Backend**: Python 3.11 + FastAPI + LangChain
- **Database**: Supabase (Postgres + pgvector)
- **LLM**: OpenAI (gpt-4o-mini, text-embedding-3-small)
- **Deployment**: Google Cloud Run (ì„œìš¸ ë¦¬ì „)
- **Secret Management**: Google Secret Manager
- **PDF Processing**: unstructured + pymupdf
- **Vector Store**: pgvector (Supabase)

---

ì´ ë‚´ìš©ì€ ê¸°ì¡´ PRD.mdì˜ AI ë¦¬íŒ©í† ë§ ë° êµ¬ì¡° ì •ì˜ë¥¼ í¬í•¨í•˜ë©°, ì‹¤ì œ ì½”ë“œ ë² ì´ìŠ¤ êµ¬ì„±ì˜ í‘œì¤€ ê°€ì´ë“œë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
