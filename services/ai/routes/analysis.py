"""
ë¶„ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° API

ì¼€ì´ìŠ¤ ìƒíƒœ ì „í™˜ê³¼ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì¡°ìœ¨í•©ë‹ˆë‹¤.
"""
import logging
import asyncio
from datetime import datetime
from typing import Optional
from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from core.supabase_client import get_supabase_client, supabase_storage
from core.auth import get_current_user
from core.risk_engine import analyze_risks  # âœ… êµ¬í˜„ ì™„ë£Œ
from core.llm_router import dual_model_analyze  # âœ… êµ¬í˜„ ì™„ë£Œ
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import SystemMessage, HumanMessage

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/analyze", tags=["analysis"])


# ===========================
# Request/Response Models
# ===========================
class StartAnalysisRequest(BaseModel):
    """ë¶„ì„ ì‹œì‘ ìš”ì²­"""
    case_id: str


class AnalysisStatusResponse(BaseModel):
    """ë¶„ì„ ìƒíƒœ ì‘ë‹µ"""
    case_id: str
    current_state: str
    progress: float  # 0.0 ~ 1.0
    message: str


class AnalysisResultResponse(BaseModel):
    """ë¶„ì„ ê²°ê³¼ ì‘ë‹µ"""
    case_id: str
    report_id: Optional[str]
    risks: Optional[list] = None
    recommendations: Optional[list] = None
    summary: Optional[str] = None


class CrosscheckRequest(BaseModel):
    """êµì°¨ê²€ì¦ ìš”ì²­ (Claude ê²€ì¦ ì „ìš©)"""
    draft: str


class CrosscheckResponse(BaseModel):
    """êµì°¨ê²€ì¦ ì‘ë‹µ"""
    validation: str


class AuditLogEntry(BaseModel):
    """ê°ì‚¬ ë¡œê·¸ í•­ëª©"""
    id: str
    event_type: str
    event_category: str
    message: str
    severity: str
    created_at: str
    metadata: Optional[dict] = None


class AuditLogsResponse(BaseModel):
    """ê°ì‚¬ ë¡œê·¸ ëª©ë¡ ì‘ë‹µ"""
    case_id: str
    total_count: int
    logs: list[AuditLogEntry]


# ===========================
# ìƒíƒœ ì „í™˜ ë§¤í•‘
# ===========================
STATE_TRANSITIONS = {
    "init": "address_pick",
    "address_pick": "contract_type",
    "contract_type": "registry_choice",
    "registry_choice": "registry_ready",
    "registry_ready": "parse_enrich",
    "parse_enrich": "report",
}

STATE_PROGRESS = {
    "init": 0.0,
    "address_pick": 0.15,
    "contract_type": 0.3,
    "registry_choice": 0.45,
    "registry_ready": 0.6,
    "parse_enrich": 0.8,
    "report": 1.0,
}


# ===========================
# API Endpoints
# ===========================
class SimpleChatRequest(BaseModel):
    """ê°„ë‹¨í•œ ì±„íŒ… ì§ˆë¬¸ ìš”ì²­"""
    question: str


class SimpleChatResponse(BaseModel):
    """ê°„ë‹¨í•œ ì±„íŒ… ì‘ë‹µ"""
    answer: str
    confidence: Optional[float] = None


@router.post("/", response_model=SimpleChatResponse)
async def simple_chat_analysis(
    request: SimpleChatRequest,
    user: dict = Depends(get_current_user)
):
    """
    ê°„ë‹¨í•œ ì±„íŒ… ì§ˆë¬¸ ë¶„ì„ (ì¼€ì´ìŠ¤ ì—†ì´ ì¦‰ì‹œ ì‘ë‹µ)

    - ë¶€ë™ì‚° ê´€ë ¨ ì¼ë°˜ ì§ˆë¬¸ì— ë‹µë³€
    - LLM ë“€ì–¼ ì‹œìŠ¤í…œ (ChatGPT + Claude) ì‚¬ìš©
    - ë“±ê¸°ë¶€/ê³µê³µë°ì´í„° ì—†ì´ ë‹µë³€ ê°€ëŠ¥
    """
    logger.info(f"ê°„ë‹¨ ì±„íŒ… ë¶„ì„: user_id={user['sub']}, question={request.question[:50]}...")

    try:
        # ê·œì¹™ ê¸°ë°˜ ê²Œì´íŠ¸ ì´í›„ì˜ ê°„ë‹¨ Q&AëŠ” ChatGPT(OpenAI) ë‹¨ì¼ ëª¨ë¸ë§Œ ì‚¬ìš©
        # (ë¦¬í¬íŠ¸ ìƒì„±/ê²€í†  ë‹¨ê³„ì—ì„œë§Œ Claude ê°œì…)
        context = """
ë¶€ë™ì‚° ê³„ì•½ ë¦¬ìŠ¤í¬ ë¶„ì„ ì „ë¬¸ ìƒë‹´ì…ë‹ˆë‹¤.

ì¼ë°˜ì ì¸ ë¶€ë™ì‚° ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ê³„ì•½ì„œë‚˜ ë“±ê¸°ë¶€ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°, ì •ì‹ ì¼€ì´ìŠ¤ ë¶„ì„ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
"""

        # single_model_analyzeëŠ” ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ ì‹¤í–‰ê¸°ì—ì„œ ì‹¤í–‰
        from core.llm_router import single_model_analyze
        loop = asyncio.get_running_loop()
        single = await loop.run_in_executor(
            None,
            lambda: single_model_analyze(
                question=request.question,
                context=context,
                provider="openai",
            ),
        )

        logger.info("ê°„ë‹¨ ë‹µë³€ ìƒì„± ì™„ë£Œ (provider=openai)")

        return SimpleChatResponse(
            answer=single.content,
            confidence=None,
        )

    except Exception as e:
        logger.error(f"ê°„ë‹¨ ì±„íŒ… ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(500, f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}")


@router.post("/start", response_model=AnalysisStatusResponse)
async def start_analysis(
    request: StartAnalysisRequest,
    user: dict = Depends(get_current_user)
):
    """
    ë¶„ì„ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)

    - ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… íì— ë¶„ì„ íƒœìŠ¤í¬ ë“±ë¡
    - ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©ì€ /analyze/stream ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
    """
    logger.info(f"â–¶ [start_analysis] ìš”ì²­ ë°›ìŒ")
    logger.info(f"   â””â”€ case_id={request.case_id}")
    logger.info(f"   â””â”€ user_id={user['sub']}")

    supabase = get_supabase_client(service_role=True)

    # ì¼€ì´ìŠ¤ ì¡°íšŒ
    case_response = supabase.table("v2_cases") \
        .select("*") \
        .eq("id", str(request.case_id)) \
        .eq("user_id", str(user["sub"])) \
        .execute()

    if not case_response.data:
        raise HTTPException(404, "Case not found")

    case = case_response.data[0]
    current_state = case["current_state"]

    # ìƒíƒœ ê²€ì¦: parse_enrich ìƒíƒœì—ì„œë§Œ ë¶„ì„ ì‹œì‘ ê°€ëŠ¥
    if current_state != "parse_enrich":
        raise HTTPException(
            400,
            f"Cannot start analysis from state '{current_state}'. Expected 'parse_enrich'."
        )

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë¹„ë¸”ë¡œí‚¹)
    import asyncio
    asyncio.create_task(execute_analysis_pipeline(request.case_id))

    return AnalysisStatusResponse(
        case_id=request.case_id,
        current_state="parse_enrich",
        progress=STATE_PROGRESS["parse_enrich"],
        message="ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©ì€ /analyze/streamì„ ì‚¬ìš©í•˜ì„¸ìš”.",
    )


@router.get("/stream/{case_id}")
async def stream_analysis(
    case_id: str,
    user: dict = Depends(get_current_user)
):
    """
    ì‹¤ì‹œê°„ ë¶„ì„ ìŠ¤íŠ¸ë¦¬ë° (Server-Sent Events)

    - ë“±ê¸°ë¶€ íŒŒì‹±, ë¦¬ìŠ¤í¬ ê³„ì‚°, LLM ìƒì„± ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°
    - ChatGPTì²˜ëŸ¼ ìƒê°í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤Œ
    """
    from fastapi.responses import StreamingResponse
    import json

    async def event_generator():
        """SSE ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ìƒì„±"""
        try:
            # 1ë‹¨ê³„: ì‹œì‘
            yield f"data: {json.dumps({'step': 1, 'message': 'ğŸš€ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...', 'progress': 0.1}, ensure_ascii=False)}\n\n"
            await asyncio.sleep(0.5)

            # 2ë‹¨ê³„: ì¼€ì´ìŠ¤ ë°ì´í„° ì¡°íšŒ
            yield f"data: {json.dumps({'step': 2, 'message': 'ğŸ“‹ ì¼€ì´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì¤‘...', 'progress': 0.2}, ensure_ascii=False)}\n\n"

            supabase = get_supabase_client(service_role=True)
            case_response = supabase.table("v2_cases").select("*").eq("id", case_id).execute()

            if not case_response.data:
                yield f"data: {json.dumps({'error': 'ì¼€ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, ensure_ascii=False)}\n\n"
                return

            case = case_response.data[0]
            address = case.get("property_address", "N/A")
            yield f"data: {json.dumps({'step': 2, 'message': f'âœ… ì¼€ì´ìŠ¤ ì¡°íšŒ ì™„ë£Œ: {address}', 'progress': 0.25}, ensure_ascii=False)}\n\n"
            await asyncio.sleep(0.5)

            # 3ë‹¨ê³„: ë“±ê¸°ë¶€ íŒŒì‹±
            yield f"data: {json.dumps({'step': 3, 'message': 'ğŸ“„ ë“±ê¸°ë¶€ íŒŒì‹± ì¤‘...', 'progress': 0.3}, ensure_ascii=False)}\n\n"

            artifact_response = supabase.table("v2_artifacts") \
                .select("*") \
                .eq("case_id", case_id) \
                .eq("artifact_type", "registry_pdf") \
                .execute()

            registry_data = None
            registry_doc_masked = None
            registry_doc = None

            if artifact_response.data:
                from ingest.registry_parser import parse_registry_from_url
                from core.risk_engine import RegistryData

                # ë™ì  Signed URL ìƒì„± (1ì‹œê°„ ë§Œë£Œ)
                file_path = artifact_response.data[0].get("file_path")
                if file_path:
                    bucket, path = file_path.split("/", 1)
                    registry_url = await supabase_storage.get_signed_url(bucket, path, expires_in=3600)
                    # ê°ì‚¬ ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                    registry_doc = await parse_registry_from_url(registry_url, case_id=case_id, user_id=case['user_id'])

                    # RegistryData ëª¨ë¸ë¡œ ë³€í™˜
                    registry_data = RegistryData(
                        property_value=None,
                        mortgage_total=sum([m.amount or 0 for m in registry_doc.mortgages]),
                        seizure_exists=any(s.type == "ì••ë¥˜" for s in registry_doc.seizures),
                        provisional_attachment_exists=any(s.type == "ê°€ì••ë¥˜" for s in registry_doc.seizures),
                        ownership_disputes=False
                    )

                    registry_doc_masked = registry_doc.to_masked_dict()

                    # ë“±ê¸°ë¶€ ìš”ì•½ ì •ë³´ ì „ì†¡
                    summary = f"âœ… ë“±ê¸°ë¶€ íŒŒì‹± ì™„ë£Œ\n"
                    summary += f"   ğŸ“ ì£¼ì†Œ: {registry_doc.property_address or 'N/A'}\n"
                    summary += f"   ğŸ‘¤ ì†Œìœ ì: {registry_doc_masked['owner']['name'] if registry_doc_masked.get('owner') else 'N/A'}\n"
                    summary += f"   ğŸ’° ê·¼ì €ë‹¹: {len(registry_doc.mortgages)}ê±´ (ì´ {registry_data.mortgage_total:,}ë§Œì›)\n"

                    if registry_doc.seizures:
                        summary += f"   âš ï¸ ì••ë¥˜/ê°€ì••ë¥˜: {len(registry_doc.seizures)}ê±´\n"

                    yield f"data: {json.dumps({'step': 3, 'message': summary, 'progress': 0.4, 'registry_summary': registry_doc_masked}, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(1.0)

            # 4ë‹¨ê³„: ê³µê³µë°ì´í„° ì¡°íšŒ
            yield f"data: {json.dumps({'step': 4, 'message': 'ğŸ” ê³µê³µë°ì´í„° ì¡°íšŒ ì¤‘ (ì‹¤ê±°ë˜ê°€, ë²•ì •ë™ì½”ë“œ)...', 'progress': 0.5}, ensure_ascii=False)}\n\n"

            from core.public_data_api import AptTradeAPIClient, LegalDongCodeAPIClient
            from core.settings import settings
            import httpx
            from datetime import datetime

            property_value_estimate = None
            async with httpx.AsyncClient() as client:
                legal_dong_client = LegalDongCodeAPIClient(
                    api_key=settings.public_data_api_key,
                    client=client
                )
                legal_dong_result = await legal_dong_client.get_legal_dong_code(
                    keyword=case['property_address']
                )

                lawd_cd = None
                if legal_dong_result['body']['items']:
                    lawd_cd = legal_dong_result['body']['items'][0]['lawd5']
                    yield f"data: {json.dumps({'step': 4, 'message': f'âœ… ë²•ì •ë™ì½”ë“œ: {lawd_cd}', 'progress': 0.55}, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0.5)

                if lawd_cd:
                    apt_trade_client = AptTradeAPIClient(
                        api_key=settings.public_data_api_key,
                        client=client
                    )
                    now = datetime.now()
                    trade_result = await apt_trade_client.get_apt_trades(
                        lawd_cd=lawd_cd,
                        deal_ymd=f"{now.year}{now.month:02d}"
                    )

                    if trade_result['body']['items']:
                        amounts = [item['dealAmount'] for item in trade_result['body']['items']
                                  if item['dealAmount']]
                        if amounts:
                            property_value_estimate = sum(amounts) // len(amounts)
                            yield f"data: {json.dumps({'step': 4, 'message': f'âœ… í‰ê·  ì‹¤ê±°ë˜ê°€: {property_value_estimate:,}ë§Œì› ({len(amounts)}ê±´ ë¶„ì„)', 'progress': 0.6}, ensure_ascii=False)}\n\n"
                            await asyncio.sleep(0.5)

            # registry_data ì—…ë°ì´íŠ¸
            if registry_data and property_value_estimate:
                from core.risk_engine import PropertyType, get_default_auction_rate

                contract_type = case.get('contract_type', 'ì „ì„¸')
                property_type = case.get('metadata', {}).get('property_type')
                sido = case.get('metadata', {}).get('sido')
                sigungu = case.get('metadata', {}).get('sigungu')
                auction_rate_override = case.get('metadata', {}).get('auction_rate_override')

                if contract_type in ["ì „ì„¸", "ì›”ì„¸"]:
                    auction_rate = 0.70
                    if auction_rate_override is not None:
                        auction_rate = auction_rate_override
                    elif property_type and sido and sigungu:
                        auction_rate = get_default_auction_rate(
                            property_type=PropertyType(property_type),
                            sido=sido,
                            sigungu=sigungu
                        )

                    registry_data.property_value = int(property_value_estimate * auction_rate)
                    yield f"data: {json.dumps({'step': 4, 'message': f'âœ… ë¬¼ê±´ ê°€ì¹˜ ê³„ì‚°: {property_value_estimate:,}ë§Œì› Ã— {auction_rate * 100:.0f}% = {registry_data.property_value:,}ë§Œì›', 'progress': 0.65}, ensure_ascii=False)}\n\n"
                else:
                    registry_data.property_value = property_value_estimate

            # 5ë‹¨ê³„: ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚°
            yield f"data: {json.dumps({'step': 5, 'message': 'ğŸ“Š ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚° ì¤‘...', 'progress': 0.7}, ensure_ascii=False)}\n\n"

            from core.risk_engine import analyze_risks, ContractData, PropertyType

            contract_type = case.get('contract_type', 'ì „ì„¸')
            property_type = case.get('metadata', {}).get('property_type')
            sido = case.get('metadata', {}).get('sido')
            sigungu = case.get('metadata', {}).get('sigungu')
            auction_rate_override = case.get('metadata', {}).get('auction_rate_override')

            contract_data = ContractData(
                contract_type=contract_type,
                deposit=case.get('metadata', {}).get('deposit'),
                price=case.get('metadata', {}).get('price'),
                property_address=case.get('property_address') if contract_type == 'ë§¤ë§¤' else None,
                property_type=PropertyType(property_type) if property_type else None,
                sido=sido,
                sigungu=sigungu,
                auction_rate_override=auction_rate_override,
            )

            risk_result = None
            if contract_type == 'ë§¤ë§¤':
                from core.risk_engine import MarketData
                market_data = MarketData(
                    avg_trade_price=property_value_estimate,
                    recent_trades=[],
                    avg_price_per_pyeong=None,
                ) if property_value_estimate else None

                risk_result = analyze_risks(contract_data, registry=registry_data, market=market_data, property_value=None)
            else:
                if registry_data:
                    risk_result = analyze_risks(contract_data, registry_data)

            if risk_result:
                risk_message = f"âœ… ë¦¬ìŠ¤í¬ ë¶„ì„ ì™„ë£Œ\n"
                risk_message += f"   ğŸ“Š ì´ì : {risk_result.risk_score.total_score:.1f}ì \n"
                risk_message += f"   ğŸ¯ ìœ„í—˜ ë“±ê¸‰: {risk_result.risk_score.risk_level}\n"

                if risk_result.risk_score.jeonse_ratio:
                    risk_message += f"   ğŸ’° ì „ì„¸ê°€ìœ¨: {risk_result.risk_score.jeonse_ratio:.1f}%\n"

                if risk_result.risk_score.mortgage_ratio:
                    risk_message += f"   ğŸ¦ ê·¼ì €ë‹¹ ë¹„ìœ¨: {risk_result.risk_score.mortgage_ratio:.1f}%\n"

                yield f"data: {json.dumps({'step': 5, 'message': risk_message, 'progress': 0.75, 'risk_score': risk_result.risk_score.dict()}, ensure_ascii=False)}\n\n"
                await asyncio.sleep(1.0)

            # 6ë‹¨ê³„: LLM ë¦¬í¬íŠ¸ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
            yield f"data: {json.dumps({'step': 6, 'message': 'ğŸ¤– AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ (GPT-4o-mini)...', 'progress': 0.8}, ensure_ascii=False)}\n\n"

            from core.report_generator import build_risk_features_from_registry, build_llm_prompt
            from langchain_openai import ChatOpenAI
            from langchain_core.messages import HumanMessage

            risk_features = None
            if artifact_response.data and registry_url and registry_doc:
                risk_features = build_risk_features_from_registry(
                    registry_doc=registry_doc,
                    contract_deposit=case.get('metadata', {}).get('deposit'),
                    contract_price=case.get('metadata', {}).get('price'),
                    property_value=registry_data.property_value if registry_data else None
                )

            llm_prompt = None
            if risk_features:
                llm_prompt = build_llm_prompt(
                    risk_features=risk_features,
                    contract_type=contract_type,
                    contract_deposit=case.get('metadata', {}).get('deposit'),
                    contract_price=case.get('metadata', {}).get('price'),
                    monthly_rent=case.get('metadata', {}).get('monthly_rent')
                )
            else:
                llm_prompt = f"""# ë¶€ë™ì‚° ê³„ì•½ ë¶„ì„ ìš”ì²­

**ì£¼ì†Œ**: {case['property_address']}
**ê³„ì•½ ìœ í˜•**: {contract_type}

**ë“±ê¸°ë¶€ ì •ë³´**: ì—†ìŒ

ìœ„ ì •ë³´ë§Œìœ¼ë¡œ ê°„ë‹¨í•œ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”."""

            # LLM ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
            llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3, max_tokens=4096, streaming=True)
            messages = [HumanMessage(content=llm_prompt)]

            # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë¦¬í¬íŠ¸ ìƒì„± ê³¼ì • ì‹¤ì‹œê°„ ì „ì†¡
            final_answer = ""
            chunk_count = 0

            async for chunk in llm.astream(messages):
                if hasattr(chunk, 'content') and chunk.content:
                    final_answer += chunk.content
                    chunk_count += 1

                    # 10ê°œ ì²­í¬ë§ˆë‹¤ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ (ë„ˆë¬´ ìì£¼ ë³´ë‚´ì§€ ì•Šë„ë¡)
                    if chunk_count % 10 == 0:
                        progress = 0.8 + (min(len(final_answer), 2000) / 2000) * 0.1  # 0.8 ~ 0.9
                        event_data = {
                            'step': 6,
                            'message': f'ğŸ“ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘... ({len(final_answer)}ì)',
                            'progress': progress,
                            'partial_content': final_answer[:200] + '...'
                        }
                        yield f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"

            # ìƒì„± ì™„ë£Œ
            event_data_complete = {
                'step': 6,
                'message': f'âœ… AI ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ ({len(final_answer)}ì)',
                'progress': 0.9
            }
            yield f"data: {json.dumps(event_data_complete, ensure_ascii=False)}\n\n"
            await asyncio.sleep(0.5)

            # 7ë‹¨ê³„: ë¦¬í¬íŠ¸ ì €ì¥
            yield f"data: {json.dumps({'step': 7, 'message': 'ğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥ ì¤‘...', 'progress': 0.95}, ensure_ascii=False)}\n\n"

            market_data = None
            report_response = supabase.table("v2_reports").insert({
                "case_id": case_id,
                "user_id": case['user_id'],
                "content": final_answer,
                "risk_score": risk_result.risk_score.dict() if risk_result else {},
                "registry_data": registry_doc_masked,
                "report_data": {
                    "summary": final_answer,
                    "risk": risk_result.risk_score.dict() if risk_result else {},
                    "registry": registry_doc_masked,
                    "market": market_data.dict() if (contract_type == 'ë§¤ë§¤' and market_data) else None
                },
                "metadata": {
                    "model": "gpt-4o-mini",
                    "confidence": 0.85,
                }
            }).execute()

            if not report_response.data:
                yield f"data: {json.dumps({'error': 'ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨'}, ensure_ascii=False)}\n\n"
                return

            report_id = report_response.data[0]['id']
            logger.info(f"âœ… [SSE] ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: case_id={case_id}, user_id={case['user_id']}, report_id={report_id}")

            # 8ë‹¨ê³„: ìƒíƒœ ì „í™˜
            supabase.table("v2_cases").update({
                "current_state": "report",
                "updated_at": datetime.utcnow().isoformat(),
            }).eq("id", case_id).execute()

            # âœ… ê²€ì¦ ë‹¨ê³„ ì¶”ê°€ (SSE_REPORT_DEBUG.md ë°©ì•ˆ 1)
            # 8-1: v2_reports ì¬í™•ì¸ (Supabase ë¦¬í”Œë¦¬ì¼€ì´ì…˜ ì§€ì—° ê°ì§€)
            verify_report = supabase.table("v2_reports") \
                .select("id") \
                .eq("id", report_id) \
                .execute()

            if not verify_report.data:
                logger.error(f"âŒ [SSE ê²€ì¦ ì‹¤íŒ¨] ë¦¬í¬íŠ¸ ê²€ì¦ ì‹¤íŒ¨: report_id={report_id}")
                yield f"data: {json.dumps({'error': 'ë¦¬í¬íŠ¸ ì €ì¥ ê²€ì¦ ì‹¤íŒ¨. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'}, ensure_ascii=False)}\n\n"
                return

            # 8-2: v2_cases current_state ì¬í™•ì¸
            verify_case = supabase.table("v2_cases") \
                .select("current_state") \
                .eq("id", case_id) \
                .execute()

            if not verify_case.data or verify_case.data[0]['current_state'] != 'report':
                current = verify_case.data[0]['current_state'] if verify_case.data else 'unknown'
                logger.error(f"âŒ [SSE ê²€ì¦ ì‹¤íŒ¨] ì¼€ì´ìŠ¤ ìƒíƒœ ê²€ì¦ ì‹¤íŒ¨: case_id={case_id}, current_state={current}")
                yield f"data: {json.dumps({'error': 'ì¼€ì´ìŠ¤ ìƒíƒœ ì „í™˜ ì‹¤íŒ¨. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'}, ensure_ascii=False)}\n\n"
                return

            logger.info(f"âœ… [SSE ê²€ì¦ í†µê³¼] ë¦¬í¬íŠ¸ ë° ìƒíƒœ ì „í™˜ í™•ì¸ ì™„ë£Œ")

            # ì™„ë£Œ (ê²€ì¦ í†µê³¼ í›„ì—ë§Œ ì „ì†¡)
            yield f"data: {json.dumps({'step': 8, 'message': 'âœ… ë¶„ì„ ì™„ë£Œ!', 'progress': 1.0, 'report_id': report_id, 'done': True}, ensure_ascii=False)}\n\n"

        except Exception as e:
            logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
            yield f"data: {json.dumps({'error': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'}, ensure_ascii=False)}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")


# Alias: POST /analyze (guide compatibility)
@router.post("", response_model=AnalysisStatusResponse)
async def analyze_alias(
    request: StartAnalysisRequest,
    user: dict = Depends(get_current_user)
):
    """
    Guide í˜¸í™˜ìš© ë³„ì¹­ ì—”ë“œí¬ì¸íŠ¸.

    - POST /analyze â†’ ë‚´ë¶€ì ìœ¼ë¡œ /analyze/startì™€ ë™ì¼ ë™ì‘
    """
    return await start_analysis(request, user)


@router.get("/status/{case_id}", response_model=AnalysisStatusResponse)
async def get_analysis_status(
    case_id: str,
    user: dict = Depends(get_current_user)
):
    """
    ë¶„ì„ ìƒíƒœ ì¡°íšŒ

    - í˜„ì¬ ì¼€ì´ìŠ¤ ìƒíƒœì™€ ì§„í–‰ë¥  ë°˜í™˜
    """
    supabase = get_supabase_client()

    case_response = supabase.table("v2_cases") \
        .select("*") \
        .eq("id", case_id) \
        .eq("user_id", user["sub"]) \
        .execute()

    if not case_response.data:
        raise HTTPException(404, "Case not found")

    case = case_response.data[0]
    current_state = case["current_state"]

    messages = {
        "init": "ì‹œì‘í•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬ ì§„í–‰í•˜ì„¸ìš”.",
        "address_pick": "ë¶€ë™ì‚° ì£¼ì†Œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
        "contract_type": "ê³„ì•½ ìœ í˜•ì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
        "registry_choice": "ë“±ê¸°ë¶€ ë°œê¸‰ ë˜ëŠ” ì—…ë¡œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.",
        "registry_ready": "ë“±ê¸°ë¶€ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "parse_enrich": "ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...",
        "report": "ë¦¬í¬íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.",
    }

    return AnalysisStatusResponse(
        case_id=case_id,
        current_state=current_state,
        progress=STATE_PROGRESS.get(current_state, 0.0),
        message=messages.get(current_state, "ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœì…ë‹ˆë‹¤."),
    )


@router.post("/transition/{case_id}", response_model=AnalysisStatusResponse)
async def transition_state(
    case_id: str,
    target_state: str,
    user: dict = Depends(get_current_user)
):
    """
    ìƒíƒœ ì „í™˜ (ë””ë²„ê¹…/í…ŒìŠ¤íŠ¸ìš©)

    - ìˆ˜ë™ìœ¼ë¡œ ì¼€ì´ìŠ¤ ìƒíƒœë¥¼ ì „í™˜
    - í”„ë¡œë•ì…˜ì—ì„œëŠ” ìë™ ì „í™˜ ì‚¬ìš© ê¶Œì¥
    """
    supabase = get_supabase_client()

    # ìœ íš¨í•œ ìƒíƒœì¸ì§€ í™•ì¸
    valid_states = list(STATE_TRANSITIONS.keys()) + ["report"]
    if target_state not in valid_states:
        raise HTTPException(400, f"Invalid state: {target_state}")

    # ì¼€ì´ìŠ¤ ì—…ë°ì´íŠ¸
    update_response = supabase.table("v2_cases") \
        .update({
            "current_state": target_state,
            "updated_at": datetime.utcnow().isoformat(),
        }) \
        .eq("id", case_id) \
        .eq("user_id", user["sub"]) \
        .execute()

    if not update_response.data:
        raise HTTPException(404, "Case not found or update failed")

    return AnalysisStatusResponse(
        case_id=case_id,
        current_state=target_state,
        progress=STATE_PROGRESS.get(target_state, 0.0),
        message=f"ìƒíƒœê°€ '{target_state}'ë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
    )


@router.get("/result/{case_id}", response_model=AnalysisResultResponse)
async def get_analysis_result(
    case_id: str,
    user: dict = Depends(get_current_user)
):
    """
    ë¶„ì„ ê²°ê³¼ ì¡°íšŒ

    - ì™„ë£Œëœ ë¶„ì„ì˜ ë¦¬í¬íŠ¸ ë°˜í™˜
    - TODO: Phase 3ì—ì„œ ë¦¬í¬íŠ¸ ì‹œìŠ¤í…œ êµ¬í˜„
    """
    supabase = get_supabase_client()

    # ì¼€ì´ìŠ¤ ì¡°íšŒ
    case_response = supabase.table("v2_cases") \
        .select("*") \
        .eq("id", case_id) \
        .eq("user_id", user["sub"]) \
        .execute()

    if not case_response.data:
        raise HTTPException(404, "Case not found")

    case = case_response.data[0]

    # ë¶„ì„ ì™„ë£Œ ì—¬ë¶€ í™•ì¸
    if case["current_state"] not in ["report", "completed"]:
        raise HTTPException(
            400,
            f"Analysis not completed. Current state: {case['current_state']}"
        )

    # TODO: v2_reports í…Œì´ë¸”ì—ì„œ ë¦¬í¬íŠ¸ ì¡°íšŒ
    # report_response = supabase.table("v2_reports") \
    #     .select("*") \
    #     .eq("case_id", case_id) \
    #     .execute()

    # ì„ì‹œ ì‘ë‹µ (Phase 3ì—ì„œ ì‹¤ì œ ë¦¬í¬íŠ¸ ë°˜í™˜)
    return AnalysisResultResponse(
        case_id=case_id,
        report_id=None,
        risks=None,
        recommendations=None,
        summary="ë¶„ì„ ê²°ê³¼ëŠ” Phase 3ì—ì„œ êµ¬í˜„ë©ë‹ˆë‹¤.",
    )


@router.post("/crosscheck", response_model=CrosscheckResponse)
async def crosscheck_draft(
    request: CrosscheckRequest,
    user: dict = Depends(get_current_user)
):
    """
    Guide í˜¸í™˜ìš©: Claudeë¡œ ì´ˆì•ˆì„ êµì°¨ê²€ì¦.
    """
    judge_prompt = """ë„ˆëŠ” ë¶€ë™ì‚° ê³„ì•½ ë¦¬ìŠ¤í¬ ì ê²€ ê²€ì¦ìì´ë‹¤.

ë‹¤ìŒì€ ChatGPTê°€ ìƒì„±í•œ ì´ˆì•ˆì´ë‹¤:

{draft}

ì´ ì´ˆì•ˆì„ ë‹¤ìŒ ê´€ì ì—ì„œ ê²€ì¦í•˜ë¼:
1. ì‚¬ì‹¤ ê´€ê³„ì˜ ì •í™•ì„±
2. ë²•ë¥ ì  í‘œí˜„ì˜ ì ì ˆì„±
3. ëˆ„ë½ëœ ì¤‘ìš” ë¦¬ìŠ¤í¬
4. ê¶Œì¥ ì¡°ì¹˜ì˜ ì‹¤íš¨ì„±

ê²€ì¦ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ë¼:

### ê²€ì¦ ê²°ê³¼
- ì •í™•í•œ ë‚´ìš©: ...
- ìˆ˜ì • í•„ìš”: ...
- ì¶”ê°€ í•„ìš”: ...

### ìµœì¢… ê¶Œì¥ì‚¬í•­
...
"""
    llm = ChatAnthropic(model="claude-3-5-sonnet-latest", temperature=0.1, max_tokens=4096)
    msgs = [
        SystemMessage(content=judge_prompt.format(draft=request.draft)),
        HumanMessage(content="ê²€ï¿½ï¿½ì„ ìˆ˜í–‰í•˜ì„¸ìš”."),
    ]
    resp = llm.invoke(msgs)
    return CrosscheckResponse(validation=resp.content)


@router.get("/audit-logs/{case_id}", response_model=AuditLogsResponse)
async def get_audit_logs(
    case_id: str,
    severity: Optional[str] = None,
    category: Optional[str] = None,
    limit: int = 50,
    user: dict = Depends(get_current_user)
):
    """
    ì¼€ì´ìŠ¤ ê°ì‚¬ ë¡œê·¸ ì¡°íšŒ

    - íŒŒì‹± ì—ëŸ¬, ê²½ê³ , ì„±ê³µ ì´ë²¤íŠ¸ ë“±ì„ ì¡°íšŒ
    - severity í•„í„°: error, warning, info ë“±
    - category í•„í„°: parsing, registry, llm ë“±

    Args:
        case_id: ì¼€ì´ìŠ¤ UUID
        severity: ì‹¬ê°ë„ í•„í„° (ì„ íƒ)
        category: ì¹´í…Œê³ ë¦¬ í•„í„° (ì„ íƒ)
        limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 50)
        user: í˜„ì¬ ì‚¬ìš©ì

    Returns:
        ê°ì‚¬ ë¡œê·¸ ëª©ë¡
    """
    supabase = get_supabase_client(service_role=True)

    # ì¼€ì´ìŠ¤ ê¶Œí•œ í™•ì¸
    case_response = supabase.table("v2_cases") \
        .select("id") \
        .eq("id", case_id) \
        .eq("user_id", user["sub"]) \
        .execute()

    if not case_response.data:
        raise HTTPException(404, "Case not found")

    # ê°ì‚¬ ë¡œê·¸ ì¡°íšŒ
    query = supabase.table("v2_audit_logs") \
        .select("*") \
        .eq("case_id", case_id) \
        .order("created_at", desc=True) \
        .limit(limit)

    # í•„í„° ì ìš©
    if severity:
        query = query.eq("severity", severity)

    if category:
        query = query.eq("event_category", category)

    logs_response = query.execute()

    # ì‘ë‹µ ë³€í™˜
    logs = [
        AuditLogEntry(
            id=log["id"],
            event_type=log["event_type"],
            event_category=log["event_category"],
            message=log["message"],
            severity=log["severity"],
            created_at=log["created_at"],
            metadata=log.get("metadata"),
        )
        for log in logs_response.data
    ]

    return AuditLogsResponse(
        case_id=case_id,
        total_count=len(logs),
        logs=logs,
    )


# ===========================
# í—¬í¼ í•¨ìˆ˜ (í–¥í›„ êµ¬í˜„)
# ===========================
async def queue_analysis_task(case_id: str):
    """
    ë¶„ì„ íƒœìŠ¤í¬ë¥¼ ë°±ê·¸ë¼ìš´ë“œ íì— ë“±ë¡

    TODO: Phase 2ì—ì„œ êµ¬í˜„
    - Celery, RQ, ë˜ëŠ” Cloud Tasks ì‚¬ìš©
    - ë¹„ë™ê¸° ë¶„ì„ ì²˜ë¦¬
    """
    pass


async def execute_analysis_pipeline(case_id: str):
    """
    ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    1. ì¼€ì´ìŠ¤ ë°ì´í„° ì¡°íšŒ (ì£¼ì†Œ, ê³„ì•½ì„œ, ë“±ê¸°ë¶€)
    2. ë“±ê¸°ë¶€ íŒŒì‹± ë° êµ¬ì¡°í™”
    3. ê³µê³µ ë°ì´í„° ìˆ˜ì§‘
    4. ë¦¬ìŠ¤í¬ ì—”ì§„ ì‹¤í–‰ â†’ ìœ„í—˜ ì ìˆ˜ ê³„ì‚°
    5. LLM ë“€ì–¼ ì‹œìŠ¤í…œ ì‹¤í–‰ â†’ ì´ˆì•ˆ ìƒì„± + ê²€ì¦
    6. ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ì¥
    7. ìƒíƒœ ì „í™˜: analysis â†’ report â†’ completed
    """
    from core.supabase_client import get_supabase_client
    from ingest.registry_parser import parse_registry_from_url
    from core.public_data_api import AptTradeAPIClient, LegalDongCodeAPIClient
    from core.risk_engine import analyze_risks, ContractData, RegistryData
    from core.llm_router import dual_model_analyze
    from core.settings import settings
    import httpx
    from datetime import datetime

    # Service Role Key ì‚¬ìš© (RLS ìš°íšŒ)
    supabase = get_supabase_client(service_role=True)
    logger.info(f"ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘: case_id={case_id}")

    try:
        # 1ï¸âƒ£ ì¼€ì´ìŠ¤ ë°ì´í„° ì¡°íšŒ
        case_response = supabase.table("v2_cases").select("*").eq("id", case_id).execute()
        if not case_response.data:
            raise HTTPException(404, f"Case not found: {case_id}")

        case = case_response.data[0]
        logger.info(f"ì¼€ì´ìŠ¤ ì¡°íšŒ ì™„ë£Œ: {case['property_address']}")

        # 2ï¸âƒ£ ë“±ê¸°ë¶€ íŒŒì‹± (v2_artifactsì—ì„œ registry_file_url ì¡°íšŒ)
        artifact_response = supabase.table("v2_artifacts") \
            .select("*") \
            .eq("case_id", case_id) \
            .eq("artifact_type", "registry_pdf") \
            .execute()

        registry_data = None
        registry_doc_masked = None  # ìœ ì €ì—ê²Œ ë³´ì—¬ì¤„ ë§ˆìŠ¤í‚¹ëœ ë°ì´í„°

        if artifact_response.data:
            # ë™ì  Signed URL ìƒì„± (1ì‹œê°„ ë§Œë£Œ)
            file_path = artifact_response.data[0].get("file_path")
            if file_path:
                bucket, path = file_path.split("/", 1)
                registry_url = await supabase_storage.get_signed_url(bucket, path, expires_in=3600)
                logger.info(f"ë“±ê¸°ë¶€ íŒŒì‹± ì‹œì‘: {file_path} (Signed URL ìƒì„±)")
                # ê°ì‚¬ ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                registry_doc = await parse_registry_from_url(registry_url, case_id=case_id, user_id=case['user_id'])

                # RegistryData ëª¨ë¸ë¡œ ë³€í™˜ (ë‚´ë¶€ ë¶„ì„ìš© - ì›ë³¸ ì‚¬ìš©)
                registry_data = RegistryData(
                    property_value=None,  # ê³µê³µ ë°ì´í„°ì—ì„œ ì¶”ì •
                    mortgage_total=sum([m.amount or 0 for m in registry_doc.mortgages]),
                    seizure_exists=any(s.type == "ì••ë¥˜" for s in registry_doc.seizures),
                    provisional_attachment_exists=any(s.type == "ê°€ì••ë¥˜" for s in registry_doc.seizures),
                    ownership_disputes=False  # TODO: ì†Œìœ ê¶Œ ë¶„ìŸ ê°ì§€ ë¡œì§
                )

                # ë§ˆìŠ¤í‚¹ëœ ë²„ì „ (ìœ ì € í‘œì‹œìš©)
                registry_doc_masked = registry_doc.to_masked_dict()

                logger.info(f"ë“±ê¸°ë¶€ íŒŒì‹± ì™„ë£Œ: ê·¼ì €ë‹¹ {registry_data.mortgage_total}ë§Œì›")
                logger.info(f"ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ ì™„ë£Œ: ì†Œìœ ì={registry_doc_masked['owner']['name'] if registry_doc_masked.get('owner') else None}")

        # 3ï¸âƒ£ ê³µê³µ ë°ì´í„° ìˆ˜ì§‘ (ì‹¤ê±°ë˜ê°€ë¡œ property_value ì¶”ì •)
        async with httpx.AsyncClient() as client:
            # ë²•ì •ë™ ì½”ë“œ ì¡°íšŒ
            legal_dong_client = LegalDongCodeAPIClient(
                api_key=settings.public_data_api_key,
                client=client
            )
            legal_dong_result = await legal_dong_client.get_legal_dong_code(
                keyword=case['property_address']
            )

            lawd_cd = None
            if legal_dong_result['body']['items']:
                lawd_cd = legal_dong_result['body']['items'][0]['lawd5']
                logger.info(f"ë²•ì •ë™ì½”ë“œ: {lawd_cd}")

            # ì‹¤ê±°ë˜ê°€ ì¡°íšŒ
            property_value_estimate = None
            if lawd_cd:
                apt_trade_client = AptTradeAPIClient(
                    api_key=settings.public_data_api_key,
                    client=client
                )
                now = datetime.now()
                trade_result = await apt_trade_client.get_apt_trades(
                    lawd_cd=lawd_cd,
                    deal_ymd=f"{now.year}{now.month:02d}"
                )

                # ì‹¤ê±°ë˜ê°€ í‰ê·  ê³„ì‚°
                if trade_result['body']['items']:
                    amounts = [item['dealAmount'] for item in trade_result['body']['items']
                              if item['dealAmount']]
                    if amounts:
                        property_value_estimate = sum(amounts) // len(amounts)
                        logger.info(f"ì‹¤ê±°ë˜ê°€ í‰ê· : {property_value_estimate}ë§Œì›")

        # 4ï¸âƒ£ ë¦¬ìŠ¤í¬ ì—”ì§„ ì‹¤í–‰ (ê³„ì•½ íƒ€ì…ì— ë”°ë¼ ë¶„ê¸°)
        contract_type = case.get('contract_type', 'ì „ì„¸')

        # ContractData ìƒì„± (property_type, sido, sigungu í¬í•¨)
        from core.risk_engine import PropertyType, get_default_auction_rate

        # TODO: property_type, sido, sigunguë¥¼ case metadata ë˜ëŠ” ì£¼ì†Œ íŒŒì‹±ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        # ì„ì‹œë¡œ ê¸°ë³¸ê°’ ì„¤ì • (í–¥í›„ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ë°›ê±°ë‚˜ ì£¼ì†Œ íŒŒì‹±ìœ¼ë¡œ ì¶”ì¶œ)
        property_type = case.get('metadata', {}).get('property_type')  # ì˜ˆ: "ì•„íŒŒíŠ¸"
        sido = case.get('metadata', {}).get('sido')  # ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ"
        sigungu = case.get('metadata', {}).get('sigungu')  # ì˜ˆ: "ê°•ë‚¨êµ¬"
        auction_rate_override = case.get('metadata', {}).get('auction_rate_override')  # ìˆ˜ë™ ì§€ì •ê°’

        contract_data = ContractData(
            contract_type=contract_type,
            deposit=case.get('metadata', {}).get('deposit'),
            price=case.get('metadata', {}).get('price'),
            property_address=case.get('property_address') if contract_type == 'ë§¤ë§¤' else None,
            property_type=PropertyType(property_type) if property_type else None,
            sido=sido,
            sigungu=sigungu,
            auction_rate_override=auction_rate_override,
        )

        # registry_data ì—…ë°ì´íŠ¸ (ì„ëŒ€ì°¨ ê³„ì•½ì¸ ê²½ìš° ë‚™ì°°ê°€ìœ¨ ì ìš©)
        if registry_data and property_value_estimate and contract_type in ["ì „ì„¸", "ì›”ì„¸"]:
            # ë‚™ì°°ê°€ìœ¨ ê²°ì •
            auction_rate = 0.70  # ê¸°ë³¸ê°’

            if auction_rate_override is not None:
                # ìˆ˜ë™ ì§€ì •ê°’ ìš°ì„  ì‚¬ìš©
                auction_rate = auction_rate_override
                logger.info(f"ë‚™ì°°ê°€ìœ¨ (ìˆ˜ë™ ì§€ì •): {auction_rate * 100:.1f}%")
            elif property_type and sido and sigungu:
                # ìë™ ê²°ì •
                auction_rate = get_default_auction_rate(
                    property_type=PropertyType(property_type),
                    sido=sido,
                    sigungu=sigungu
                )
                logger.info(f"ë‚™ì°°ê°€ìœ¨ (ìë™ ê²°ì •): {auction_rate * 100:.1f}% (íƒ€ì…={property_type}, ì§€ì—­={sido} {sigungu})")
            else:
                logger.warning(f"ë‚™ì°°ê°€ìœ¨ ì •ë³´ ë¶€ì¡± (ê¸°ë³¸ê°’ 70% ì‚¬ìš©): property_type={property_type}, sido={sido}, sigungu={sigungu}")

            # ë¬¼ê±´ ê°€ì¹˜ ê³„ì‚°: ì‹¤ê±°ë˜ê°€ Ã— ë‚™ì°°ê°€ìœ¨
            registry_data.property_value = int(property_value_estimate * auction_rate)
            logger.info(f"ë¬¼ê±´ ê°€ì¹˜ ê³„ì‚°: {property_value_estimate}ë§Œì› Ã— {auction_rate * 100:.1f}% = {registry_data.property_value}ë§Œì›")
        elif registry_data and property_value_estimate:
            # ë§¤ë§¤ ê³„ì•½ì€ ë‚™ì°°ê°€ìœ¨ ë¯¸ì ìš©
            registry_data.property_value = property_value_estimate

        risk_result = None
        market_data = None  # ëª¨ë“  ì¼€ì´ìŠ¤ì—ì„œ ì •ì˜

        if contract_type == 'ë§¤ë§¤':
            # ë§¤ë§¤ ê³„ì•½ ë¶„ì„
            from core.risk_engine import MarketData, PropertyValueAssessment, evaluate_property_value_with_llm

            # MarketData ìƒì„± (ê³µê³µë°ì´í„° ê¸°ë°˜)
            market_data = None
            if property_value_estimate:
                market_data = MarketData(
                    avg_trade_price=property_value_estimate,
                    recent_trades=[],  # TODO: ìµœê·¼ ê±°ë˜ ë‚´ì—­ ì¶”ê°€
                    avg_price_per_pyeong=None,  # TODO: í‰ë‹¹ê°€ ê³„ì‚°
                )
                logger.info(f"ì‹œì¥ ë°ì´í„° ìƒì„± ì™„ë£Œ: í‰ê·  ì‹¤ê±°ë˜ê°€={property_value_estimate}ë§Œì›")

            # LLM ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë¶€ë™ì‚° ê°€ì¹˜ í‰ê°€ (í•™êµ°, ê³µê¸‰ëŸ‰, ì§ì¥ ìˆ˜ìš”)
            property_value_assessment = None
            try:
                property_value_assessment = evaluate_property_value_with_llm(case['property_address'])
                logger.info(f"ë¶€ë™ì‚° ê°€ì¹˜ í‰ê°€ ì™„ë£Œ: ì´ì ={property_value_assessment.total_score}ì  "
                           f"(í•™êµ°={property_value_assessment.school_score}, "
                           f"ê³µê¸‰={property_value_assessment.supply_score}, "
                           f"ì§ì¥={property_value_assessment.job_score})")
            except Exception as e:
                logger.warning(f"ë¶€ë™ì‚° ê°€ì¹˜ í‰ê°€ ì‹¤íŒ¨ (ì¤‘ë¦½ ì ìˆ˜ë¡œ ëŒ€ì²´): {str(e)}")
                # ì‹¤íŒ¨ ì‹œ Noneìœ¼ë¡œ ìœ ì§€ (analyze_risksì—ì„œ ì¤‘ë¦½ ì ìˆ˜ ì ìš©)

            # ë§¤ë§¤ ë¦¬ìŠ¤í¬ ë¶„ì„ (ë“±ê¸°ë¶€ ì„ íƒì )
            risk_result = analyze_risks(
                contract_data,
                registry=registry_data,
                market=market_data,
                property_value=property_value_assessment
            )
            logger.info(f"ë§¤ë§¤ ë¦¬ìŠ¤í¬ ë¶„ì„ ì™„ë£Œ: ì ìˆ˜={risk_result.risk_score.total_score}, "
                       f"ë ˆë²¨={risk_result.risk_score.risk_level}")
        else:
            # ì„ëŒ€ì°¨ ê³„ì•½ ë¶„ì„ (ì „ì„¸/ì›”ì„¸)
            if registry_data:
                risk_result = analyze_risks(contract_data, registry_data)
                logger.info(f"ì„ëŒ€ì°¨ ë¦¬ìŠ¤í¬ ë¶„ì„ ì™„ë£Œ: ì ìˆ˜={risk_result.risk_score.total_score}, "
                           f"ë ˆë²¨={risk_result.risk_score.risk_level}")

        # 5ï¸âƒ£ ìƒˆ ì•„í‚¤í…ì²˜: RegistryRiskFeatures ë³€í™˜ + LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        from core.report_generator import build_risk_features_from_registry, build_llm_prompt
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import HumanMessage

        # Step 1: RegistryDocument â†’ RegistryRiskFeatures (ì½”ë“œë¡œ 100% ê³„ì‚°, LLM ì—†ìŒ)
        risk_features = None
        if artifact_response.data and registry_url:
            risk_features = build_risk_features_from_registry(
                registry_doc=registry_doc,
                contract_deposit=case.get('metadata', {}).get('deposit'),
                contract_price=case.get('metadata', {}).get('price'),
                property_value=registry_data.property_value if registry_data else None
            )
            logger.info(f"ë¦¬ìŠ¤í¬ íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ (ì½”ë“œ ê¸°ë°˜): ì´ì ={risk_features.risk_score:.1f}, "
                       f"ì „ì„¸ê°€ìœ¨={risk_features.jeonse_ratio or 'N/A'}, "
                       f"ê·¼ì €ë‹¹ë¹„ìœ¨={risk_features.mortgage_ratio or 'N/A'}")

        # Step 2: RegistryRiskFeatures â†’ LLM í”„ë¡¬í”„íŠ¸ (ë§ˆí¬ë‹¤ìš´)
        llm_prompt = None
        if risk_features:
            llm_prompt = build_llm_prompt(
                risk_features=risk_features,
                contract_type=contract_type,
                contract_deposit=case.get('metadata', {}).get('deposit'),
                contract_price=case.get('metadata', {}).get('price'),
                monthly_rent=case.get('metadata', {}).get('monthly_rent')
            )
            logger.info(f"LLM í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: {len(llm_prompt)}ì")
        else:
            # ë“±ê¸°ë¶€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
            llm_prompt = f"""
# ë¶€ë™ì‚° ê³„ì•½ ë¶„ì„ ìš”ì²­

**ì£¼ì†Œ**: {case['property_address']}
**ê³„ì•½ ìœ í˜•**: {contract_type}

**ë“±ê¸°ë¶€ ì •ë³´**: ì—†ìŒ

ìœ„ ì •ë³´ë§Œìœ¼ë¡œ ê°„ë‹¨í•œ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”. ë“±ê¸°ë¶€ê°€ ì—†ìœ¼ë¯€ë¡œ ì¼ë°˜ì ì¸ ì£¼ì˜ì‚¬í•­ì„ ì•ˆë‚´í•´ì£¼ì„¸ìš”.
"""
            logger.warning("ë“±ê¸°ë¶€ ì—†ìŒ - ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")

        # Step 3: LLM í˜¸ì¶œ (í•´ì„ë§Œ ìˆ˜í–‰, íŒŒì‹±/ê³„ì‚° ì—†ìŒ)
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3, max_tokens=4096, max_retries=0, timeout=30)
        messages = [HumanMessage(content=llm_prompt)]

        import asyncio
        final_answer = None
        last_err = None
        for attempt in range(1, 4):
            try:
                response = llm.invoke(messages)
                final_answer = response.content
                logger.info(f"LLM í•´ì„ ì™„ë£Œ (ì‹œë„ {attempt}): {len(final_answer)}ì")
                break
            except Exception as e:
                last_err = e
                logger.warning(f"LLM í˜¸ì¶œ ì‹œë„ {attempt} ì‹¤íŒ¨: {e}")
                await asyncio.sleep(min(1 * attempt, 3))

        if final_answer is None:
            raise HTTPException(503, "ë¶„ì„ì´ ì§€ì—°ë©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

        # 6ï¸âƒ£ ë¦¬í¬íŠ¸ ì €ì¥ (v2_reports í…Œì´ë¸”)
        report_response = supabase.table("v2_reports").insert({
            "case_id": case_id,
            "user_id": case['user_id'],
            "content": final_answer,
            "risk_score": risk_result.risk_score.dict() if risk_result else {},
            "registry_data": registry_doc_masked,  # ë§ˆìŠ¤í‚¹ëœ ë“±ê¸°ë¶€ ì •ë³´ ì €ì¥
            "report_data": {
                "summary": final_answer,
                "risk": risk_result.risk_score.dict() if risk_result else {},
                "registry": registry_doc_masked,
                "market": market_data.dict() if (contract_type == 'ë§¤ë§¤' and market_data) else None
            },
            "metadata": {
                "model": "gpt-4o-mini",
                "confidence": 0.85,
            }
        }).execute()

        if not report_response.data:
            raise HTTPException(500, "Failed to save report")

        report_id = report_response.data[0]['id']
        logger.info(f"ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {report_id}")

        # 7ï¸âƒ£ ëŒ€í™” ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸ (ë¶„ì„ ë¦¬í¬íŠ¸ íƒœê¹…)
        # ì´ ì¼€ì´ìŠ¤ì™€ ì—°ê²°ëœ ëŒ€í™”ë¥¼ ì°¾ì•„ì„œ is_analysis_report=TRUE, case_id ì„¤ì •
        conversation_update = supabase.table("conversations") \
            .update({
                "is_analysis_report": True,
                "case_id": case_id,
                "updated_at": datetime.utcnow().isoformat(),
            }) \
            .eq("user_id", case['user_id']) \
            .or_(f"case_id.eq.{case_id},property_address.eq.{case['property_address']}") \
            .execute()

        if conversation_update.data:
            logger.info(f"ëŒ€í™” ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(conversation_update.data)}ê°œ ëŒ€í™” â†’ ë¶„ì„ ë¦¬í¬íŠ¸ë¡œ íƒœê¹…")
        else:
            logger.warning(f"ì—…ë°ì´íŠ¸í•  ëŒ€í™”ë¥¼ ì°¾ì§€ ëª»í•¨ (case_id={case_id}, ì£¼ì†Œ={case['property_address']})")

        # 8ï¸âƒ£ ìƒíƒœ ì „í™˜: parse_enrich â†’ report
        supabase.table("v2_cases").update({
            "current_state": "report",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", case_id).execute()

        logger.info(f"ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: case_id={case_id}, report_id={report_id}")
        return report_id

    except Exception as e:
        logger.error(f"ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}", exc_info=True)
        # ìƒíƒœë¥¼ ë‹¤ì‹œ registry_readyë¡œ ë¡¤ë°±
        supabase.table("v2_cases").update({
            "current_state": "registry_ready",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", case_id).execute()
        raise

# Reload trigger: 1763539083.3081586
