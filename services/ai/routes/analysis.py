"""
ë¶„ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° API

ì¼€ì´ìŠ¤ ìƒíƒœ ì „í™˜ê³¼ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì¡°ìœ¨í•©ë‹ˆë‹¤.
"""
import logging
import asyncio
from datetime import datetime
from typing import Optional
from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from core.supabase_client import get_supabase_client, supabase_storage
from core.auth import get_current_user
from core.risk_engine import analyze_risks  # âœ… êµ¬í˜„ ì™„ë£Œ
from core.llm_router import dual_model_analyze  # âœ… êµ¬í˜„ ì™„ë£Œ
from core.prompts import build_judge_prompt
from core.analysis_pipeline import build_analysis_context
from core.llm_streaming import dual_stream_analysis
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import SystemMessage, HumanMessage

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/analyze", tags=["analysis"])


# ===========================
# ê³µí†µ í—¬í¼ í•¨ìˆ˜
# ===========================
async def merge_dual_streams(
    draft_generator,
    validation_generator_factory,
    step_base: float = 6.0,
    progress_base: float = 0.78
):
    """
    ë“€ì–¼ LLM ë³‘ë ¬ ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ë¨¸ì§€

    Args:
        draft_generator: GPT-4o-mini ì´ˆì•ˆ ìƒì„± ì œë„ˆë ˆì´í„°
        validation_generator_factory: Claude ê²€ì¦ ì œë„ˆë ˆì´í„° íŒ©í† ë¦¬ (draft_content) -> generator
        step_base: SSE ì´ë²¤íŠ¸ step ê¸°ì¤€ê°’ (ê¸°ë³¸ê°’: 6.0)
        progress_base: SSE ì´ë²¤íŠ¸ progress ê¸°ì¤€ê°’ (ê¸°ë³¸ê°’: 0.78)

    Yields:
        SSE ì´ë²¤íŠ¸ ë¬¸ìì—´ (data: {...}\n\n)

    Returns:
        Tuple[str, str, dict]: (draft_content, validation_content, last_validation_event)
    """
    import json

    draft_content = ""
    validation_content = ""
    draft_done = False
    validation_done = False
    last_validation_event = None

    draft_gen = draft_generator
    validation_gen = None
    draft_start_time = asyncio.get_event_loop().time()

    while not (draft_done and validation_done):
        try:
            # GPT ì´ˆì•ˆ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
            if not draft_done:
                try:
                    draft_event = await asyncio.wait_for(draft_gen.__anext__(), timeout=0.1)

                    if draft_event.get('done'):
                        draft_done = True
                        draft_content = draft_event.get('final_content', draft_content)

                        draft_length = len(draft_content)
                        message = f'âœ… GPT-4o-mini ì´ˆì•ˆ ì™„ë£Œ ({draft_length}ì)'
                        data = {
                            'step': step_base + 0.1,
                            'phase': 'draft',
                            'model': 'gpt-4o-mini',
                            'message': message,
                            'progress': progress_base + 0.04,
                            'draft_length': draft_length
                        }
                        yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"

                        # Claude ê²€ì¦ ì‹œì‘
                        if validation_gen is None:
                            validation_gen = validation_generator_factory(draft_content)
                            data = {
                                'step': step_base + 0.2,
                                'phase': 'validation',
                                'message': 'ğŸ” Claude Sonnet ê²€ì¦ ì‹œì‘...',
                                'progress': progress_base + 0.05
                            }
                            yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
                    else:
                        total_length = draft_event.get('total_length', 0)
                        if total_length > 0 and total_length % 100 == 0:
                            message = f'ğŸ“ ì´ˆì•ˆ ìƒì„± ì¤‘... ({total_length}ì)'
                            data = {
                                'step': step_base + 0.1,
                                'phase': 'draft',
                                'model': 'gpt-4o-mini',
                                'message': message,
                                'progress': progress_base + min(total_length / 2000, 1) * 0.04,
                                'partial_length': total_length
                            }
                            yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"

                except asyncio.TimeoutError:
                    pass
                except StopAsyncIteration:
                    draft_done = True

            # Claude ê²€ì¦ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
            if validation_gen is not None and not validation_done:
                try:
                    validation_event = await asyncio.wait_for(validation_gen.__anext__(), timeout=0.1)
                    last_validation_event = validation_event

                    if validation_event.get('done'):
                        validation_done = True
                        validation_content = validation_event.get('final_content', validation_content)

                        model_name = validation_event.get('model', 'claude-3-5-sonnet')
                        validation_length = len(validation_content)
                        message = f'âœ… {model_name} ê²€ì¦ ì™„ë£Œ ({validation_length}ì)'
                        data = {
                            'step': step_base + 0.2,
                            'phase': 'validation',
                            'model': model_name,
                            'message': message,
                            'progress': progress_base + 0.10,
                            'validation_length': validation_length
                        }
                        yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
                    else:
                        total_length = validation_event.get('total_length', 0)
                        if total_length > 0 and total_length % 100 == 0:
                            message = f'ğŸ” ê²€ì¦ ì¤‘... ({total_length}ì)'
                            data = {
                                'step': step_base + 0.2,
                                'phase': 'validation',
                                'model': validation_event.get('model', 'claude-3-5-sonnet'),
                                'message': message,
                                'progress': progress_base + 0.06 + min(total_length / 2000, 1) * 0.04,
                                'partial_length': total_length
                            }
                            yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"

                except asyncio.TimeoutError:
                    pass
                except StopAsyncIteration:
                    validation_done = True

            # ë³‘ë ¬ ê²€ì¦ ì‹œì‘ (ì´ˆì•ˆ ì‹œì‘ 3ì´ˆ í›„)
            if validation_gen is None and (asyncio.get_event_loop().time() - draft_start_time) > 3:
                if draft_content:
                    validation_gen = validation_generator_factory(draft_content)
                    data = {
                        'step': step_base + 0.2,
                        'phase': 'validation',
                        'message': 'ğŸ” Claude Sonnet ê²€ì¦ ì‹œì‘ (ë³‘ë ¬)...',
                        'progress': progress_base + 0.05
                    }
                    yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"

            await asyncio.sleep(0.05)

        except Exception as e:
            logger.error(f"ë³‘ë ¬ ìŠ¤íŠ¸ë¦¬ë° ë£¨í”„ ì˜¤ë¥˜: {e}")
            break

    # ìµœì¢… ê²°ê³¼ë¥¼ yield (async generatorëŠ” return ë¶ˆê°€)
    yield (draft_content, validation_content, last_validation_event)


# ===========================
# Request/Response Models
# ===========================
class StartAnalysisRequest(BaseModel):
    """ë¶„ì„ ì‹œì‘ ìš”ì²­"""
    case_id: str


class AnalysisStatusResponse(BaseModel):
    """ë¶„ì„ ìƒíƒœ ì‘ë‹µ"""
    case_id: str
    current_state: str
    progress: float  # 0.0 ~ 1.0
    message: str


class AnalysisResultResponse(BaseModel):
    """ë¶„ì„ ê²°ê³¼ ì‘ë‹µ"""
    case_id: str
    report_id: Optional[str]
    risks: Optional[list] = None
    recommendations: Optional[list] = None
    summary: Optional[str] = None


class CrosscheckRequest(BaseModel):
    """êµì°¨ê²€ì¦ ìš”ì²­ (Claude ê²€ì¦ ì „ìš©)"""
    draft: str


class CrosscheckResponse(BaseModel):
    """êµì°¨ê²€ì¦ ì‘ë‹µ"""
    validation: str


class AuditLogEntry(BaseModel):
    """ê°ì‚¬ ë¡œê·¸ í•­ëª©"""
    id: str
    event_type: str
    event_category: str
    message: str
    severity: str
    created_at: str
    metadata: Optional[dict] = None


class AuditLogsResponse(BaseModel):
    """ê°ì‚¬ ë¡œê·¸ ëª©ë¡ ì‘ë‹µ"""
    case_id: str
    total_count: int
    logs: list[AuditLogEntry]


# ===========================
# ìƒíƒœ ì „í™˜ ë§¤í•‘
# ===========================
STATE_TRANSITIONS = {
    "init": "address_pick",
    "address_pick": "contract_type",
    "contract_type": "registry_choice",
    "registry_choice": "registry_ready",
    "registry_ready": "parse_enrich",
    "parse_enrich": "report",
}

STATE_PROGRESS = {
    "init": 0.0,
    "address_pick": 0.15,
    "contract_type": 0.3,
    "registry_choice": 0.45,
    "registry_ready": 0.6,
    "parse_enrich": 0.8,
    "report": 1.0,
}


# ===========================
# API Endpoints
# ===========================
class SimpleChatRequest(BaseModel):
    """ê°„ë‹¨í•œ ì±„íŒ… ì§ˆë¬¸ ìš”ì²­"""
    question: str


class SimpleChatResponse(BaseModel):
    """ê°„ë‹¨í•œ ì±„íŒ… ì‘ë‹µ"""
    answer: str
    confidence: Optional[float] = None


@router.post("/", response_model=SimpleChatResponse)
async def simple_chat_analysis(
    request: SimpleChatRequest,
    user: dict = Depends(get_current_user)
):
    """
    ê°„ë‹¨í•œ ì±„íŒ… ì§ˆë¬¸ ë¶„ì„ (ì¼€ì´ìŠ¤ ì—†ì´ ì¦‰ì‹œ ì‘ë‹µ)

    - ë¶€ë™ì‚° ê´€ë ¨ ì¼ë°˜ ì§ˆë¬¸ì— ë‹µë³€
    - LLM ë“€ì–¼ ì‹œìŠ¤í…œ (ChatGPT + Claude) ì‚¬ìš©
    - ë“±ê¸°ë¶€/ê³µê³µë°ì´í„° ì—†ì´ ë‹µë³€ ê°€ëŠ¥
    """
    logger.info(f"ê°„ë‹¨ ì±„íŒ… ë¶„ì„: user_id={user['sub']}, question={request.question[:50]}...")

    try:
        # ê·œì¹™ ê¸°ë°˜ ê²Œì´íŠ¸ ì´í›„ì˜ ê°„ë‹¨ Q&AëŠ” ChatGPT(OpenAI) ë‹¨ì¼ ëª¨ë¸ë§Œ ì‚¬ìš©
        # (ë¦¬í¬íŠ¸ ìƒì„±/ê²€í†  ë‹¨ê³„ì—ì„œë§Œ Claude ê°œì…)
        context = """
ë¶€ë™ì‚° ê³„ì•½ ë¦¬ìŠ¤í¬ ë¶„ì„ ì „ë¬¸ ìƒë‹´ì…ë‹ˆë‹¤.

ì¼ë°˜ì ì¸ ë¶€ë™ì‚° ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
êµ¬ì²´ì ì¸ ê³„ì•½ì„œë‚˜ ë“±ê¸°ë¶€ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°, ì •ì‹ ì¼€ì´ìŠ¤ ë¶„ì„ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
"""

        # single_model_analyzeëŠ” ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ ì‹¤í–‰ê¸°ì—ì„œ ì‹¤í–‰
        from core.llm_router import single_model_analyze
        loop = asyncio.get_running_loop()
        single = await loop.run_in_executor(
            None,
            lambda: single_model_analyze(
                question=request.question,
                context=context,
                provider="openai",
            ),
        )

        logger.info("ê°„ë‹¨ ë‹µë³€ ìƒì„± ì™„ë£Œ (provider=openai)")

        return SimpleChatResponse(
            answer=single.content,
            confidence=None,
        )

    except Exception as e:
        logger.error(f"ê°„ë‹¨ ì±„íŒ… ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(500, f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}")


@router.post("/start", response_model=AnalysisStatusResponse)
async def start_analysis(
    request: StartAnalysisRequest,
    user: dict = Depends(get_current_user)
):
    """
    ë¶„ì„ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)

    - ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… íì— ë¶„ì„ íƒœìŠ¤í¬ ë“±ë¡
    - ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©ì€ /analyze/stream ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
    """
    logger.info(f"â–¶ [start_analysis] ìš”ì²­ ë°›ìŒ")
    logger.info(f"   â””â”€ case_id={request.case_id}")
    logger.info(f"   â””â”€ user_id={user['sub']}")

    supabase = get_supabase_client(service_role=True)

    # ì¼€ì´ìŠ¤ ì¡°íšŒ
    case_response = supabase.table("v2_cases") \
        .select("*") \
        .eq("id", str(request.case_id)) \
        .eq("user_id", str(user["sub"])) \
        .execute()

    if not case_response.data:
        raise HTTPException(404, "Case not found")

    case = case_response.data[0]
    current_state = case["current_state"]

    # ìƒíƒœ ê²€ì¦: parse_enrich ìƒíƒœì—ì„œë§Œ ë¶„ì„ ì‹œì‘ ê°€ëŠ¥
    if current_state != "parse_enrich":
        raise HTTPException(
            400,
            f"Cannot start analysis from state '{current_state}'. Expected 'parse_enrich'."
        )

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë¹„ë¸”ë¡œí‚¹)
    import asyncio
    asyncio.create_task(execute_analysis_pipeline(request.case_id))

    return AnalysisStatusResponse(
        case_id=request.case_id,
        current_state="parse_enrich",
        progress=STATE_PROGRESS["parse_enrich"],
        message="ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©ì€ /analyze/streamì„ ì‚¬ìš©í•˜ì„¸ìš”.",
    )


@router.get("/stream/{case_id}")
async def stream_analysis(
    case_id: str,
    user: dict = Depends(get_current_user)
):
    """
    ì‹¤ì‹œê°„ ë¶„ì„ ìŠ¤íŠ¸ë¦¬ë° (Server-Sent Events)

    - ë“±ê¸°ë¶€ íŒŒì‹±, ë¦¬ìŠ¤í¬ ê³„ì‚°, LLM ìƒì„± ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°
    - ChatGPTì²˜ëŸ¼ ìƒê°í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤Œ
    """
    from fastapi.responses import StreamingResponse
    import json

    async def event_generator():
        """SSE ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ìƒì„±"""
        try:
            # 1ë‹¨ê³„: ì‹œì‘
            yield f"data: {json.dumps({'step': 1, 'message': 'ğŸš€ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...', 'progress': 0.1}, ensure_ascii=False)}\n\n"
            await asyncio.sleep(0.5)

            # 2ë‹¨ê³„: ì¼€ì´ìŠ¤ ë°ì´í„° ì¡°íšŒ
            yield f"data: {json.dumps({'step': 2, 'message': 'ğŸ“‹ ì¼€ì´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì¤‘...', 'progress': 0.2}, ensure_ascii=False)}\n\n"

            supabase = get_supabase_client(service_role=True)
            case_response = supabase.table("v2_cases").select("*").eq("id", case_id).execute()

            if not case_response.data:
                yield f"data: {json.dumps({'error': 'ì¼€ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}, ensure_ascii=False)}\n\n"
                return

            case = case_response.data[0]
            address = case.get("property_address", "N/A")
            message = f'âœ… ì¼€ì´ìŠ¤ ì¡°íšŒ ì™„ë£Œ: {address}'
            yield f"data: {json.dumps({'step': 2, 'message': message, 'progress': 0.25}, ensure_ascii=False)}\n\n"
            await asyncio.sleep(0.5)

            # 3ë‹¨ê³„: ë“±ê¸°ë¶€ íŒŒì‹±
            yield f"data: {json.dumps({'step': 3, 'message': 'ğŸ“„ ë“±ê¸°ë¶€ íŒŒì‹± ì¤‘...', 'progress': 0.3}, ensure_ascii=False)}\n\n"

            artifact_response = supabase.table("v2_artifacts") \
                .select("*") \
                .eq("case_id", case_id) \
                .eq("artifact_type", "registry_pdf") \
                .execute()

            registry_data = None
            registry_doc_masked = None
            registry_doc = None

            if artifact_response.data:
                from ingest.registry_parser import parse_registry_from_url
                from core.risk_engine import RegistryData

                # ë™ì  Signed URL ìƒì„± (1ì‹œê°„ ë§Œë£Œ)
                file_path = artifact_response.data[0].get("file_path")
                if file_path:
                    bucket, path = file_path.split("/", 1)
                    registry_url = await supabase_storage.get_signed_url(bucket, path, expires_in=3600)
                    # ê°ì‚¬ ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                    registry_doc = await parse_registry_from_url(registry_url, case_id=case_id, user_id=case['user_id'])

                    # RegistryData ëª¨ë¸ë¡œ ë³€í™˜
                    registry_data = RegistryData(
                        property_value=None,
                        mortgage_total=sum([m.amount or 0 for m in registry_doc.mortgages]),
                        seizure_exists=any(s.type == "ì••ë¥˜" for s in registry_doc.seizures),
                        provisional_attachment_exists=any(s.type == "ê°€ì••ë¥˜" for s in registry_doc.seizures),
                        ownership_disputes=False
                    )

                    registry_doc_masked = registry_doc.to_masked_dict()

                    # ë“±ê¸°ë¶€ ìš”ì•½ ì •ë³´ ì „ì†¡
                    summary = f"âœ… ë“±ê¸°ë¶€ íŒŒì‹± ì™„ë£Œ\n"
                    summary += f"   ğŸ“ ì£¼ì†Œ: {registry_doc.property_address or 'N/A'}\n"
                    summary += f"   ğŸ‘¤ ì†Œìœ ì: {registry_doc_masked['owner']['name'] if registry_doc_masked.get('owner') else 'N/A'}\n"
                    summary += f"   ğŸ’° ê·¼ì €ë‹¹: {len(registry_doc.mortgages)}ê±´ (ì´ {registry_data.mortgage_total:,}ë§Œì›)\n"

                    if registry_doc.seizures:
                        summary += f"   âš ï¸ ì••ë¥˜/ê°€ì••ë¥˜: {len(registry_doc.seizures)}ê±´\n"

                    yield f"data: {json.dumps({'step': 3, 'message': summary, 'progress': 0.4, 'registry_summary': registry_doc_masked}, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(1.0)

            # 4ë‹¨ê³„: ê³µê³µë°ì´í„° ì¡°íšŒ
            yield f"data: {json.dumps({'step': 4, 'message': 'ğŸ” ê³µê³µë°ì´í„° ì¡°íšŒ ì¤‘ (ì‹¤ê±°ë˜ê°€, ë²•ì •ë™ì½”ë“œ)...', 'progress': 0.5}, ensure_ascii=False)}\n\n"

            from core.public_data_api import AptTradeAPIClient, LegalDongCodeAPIClient
            from core.settings import settings
            import httpx
            from datetime import datetime

            property_value_estimate = None
            async with httpx.AsyncClient() as client:
                legal_dong_client = LegalDongCodeAPIClient(
                    api_key=settings.public_data_api_key,
                    client=client
                )
                legal_dong_result = await legal_dong_client.get_legal_dong_code(
                    keyword=case['property_address']
                )

                lawd_cd = None
                if legal_dong_result['body']['items']:
                    lawd_cd = legal_dong_result['body']['items'][0]['lawd5']
                    message = f'âœ… ë²•ì •ë™ì½”ë“œ: {lawd_cd}'
                    yield f"data: {json.dumps({'step': 4, 'message': message, 'progress': 0.55}, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0.5)

                if lawd_cd:
                    apt_trade_client = AptTradeAPIClient(
                        api_key=settings.public_data_api_key,
                        client=client
                    )
                    now = datetime.now()
                    recent_transactions = []

                    # ë™ì  ê¸°ê°„ í™•ëŒ€ ë¡œì§: 3ê°œì›” â†’ 6ê°œì›” â†’ 12ê°œì›”
                    # - 3ê°œì›” ë‚´ ë°ì´í„° < 5ê°œ â†’ 6ê°œì›” í™•ëŒ€
                    # - 6ê°œì›” ë‚´ ë°ì´í„° < 10ê°œ â†’ 12ê°œì›” í™•ëŒ€
                    from dateutil.relativedelta import relativedelta

                    def get_previous_month(year: int, month: int, months_back: int) -> str:
                        target_date = datetime(year, month, 1) - relativedelta(months=months_back)
                        return f"{target_date.year}{target_date.month:02d}"

                    # Step 1: 3ê°œì›” ì¡°íšŒ
                    for months_back in range(3):
                        deal_ymd = get_previous_month(now.year, now.month, months_back)
                        try:
                            trade_result = await apt_trade_client.get_apt_trades(
                                lawd_cd=lawd_cd,
                                deal_ymd=deal_ymd
                            )
                            if trade_result['body']['items']:
                                recent_transactions.extend(trade_result['body']['items'])
                        except Exception as e:
                            logger.warning(f"ì‹¤ê±°ë˜ê°€ ì¡°íšŒ ì‹¤íŒ¨ ({deal_ymd}): {e}")
                            continue

                    # Step 2: 3ê°œì›” ë°ì´í„° < 5ê°œ â†’ 6ê°œì›”ê¹Œì§€ í™•ëŒ€
                    if len(recent_transactions) < 5:
                        message = f'ğŸ“Š 3ê°œì›” ë°ì´í„° {len(recent_transactions)}ê±´ (5ê°œ ë¯¸ë§Œ) â†’ 6ê°œì›”ê¹Œì§€ í™•ëŒ€ ì¡°íšŒ'
                        yield f"data: {json.dumps({'step': 4, 'message': message, 'progress': 0.56}, ensure_ascii=False)}\n\n"

                        for months_back in range(3, 6):
                            deal_ymd = get_previous_month(now.year, now.month, months_back)
                            try:
                                trade_result = await apt_trade_client.get_apt_trades(
                                    lawd_cd=lawd_cd,
                                    deal_ymd=deal_ymd
                                )
                                if trade_result['body']['items']:
                                    recent_transactions.extend(trade_result['body']['items'])
                            except Exception as e:
                                logger.warning(f"ì‹¤ê±°ë˜ê°€ ì¡°íšŒ ì‹¤íŒ¨ ({deal_ymd}): {e}")
                                continue

                    # Step 3: 6ê°œì›” ë°ì´í„° < 10ê°œ â†’ 12ê°œì›”ê¹Œì§€ í™•ëŒ€
                    if len(recent_transactions) < 10:
                        message = f'ğŸ“Š 6ê°œì›” ë°ì´í„° {len(recent_transactions)}ê±´ (10ê°œ ë¯¸ë§Œ) â†’ 12ê°œì›”ê¹Œì§€ í™•ëŒ€ ì¡°íšŒ'
                        yield f"data: {json.dumps({'step': 4, 'message': message, 'progress': 0.58}, ensure_ascii=False)}\n\n"

                        for months_back in range(6, 12):
                            deal_ymd = get_previous_month(now.year, now.month, months_back)
                            try:
                                trade_result = await apt_trade_client.get_apt_trades(
                                    lawd_cd=lawd_cd,
                                    deal_ymd=deal_ymd
                                )
                                if trade_result['body']['items']:
                                    recent_transactions.extend(trade_result['body']['items'])
                            except Exception as e:
                                logger.warning(f"ì‹¤ê±°ë˜ê°€ ì¡°íšŒ ì‹¤íŒ¨ ({deal_ymd}): {e}")
                                continue

                    if recent_transactions:
                        amounts = [item['dealAmount'] for item in recent_transactions
                                  if item.get('dealAmount')]
                        if amounts:
                            property_value_estimate = sum(amounts) // len(amounts)
                            period_text = "3ê°œì›”" if len(recent_transactions) < 10 else ("6ê°œì›”" if len(recent_transactions) < 20 else "12ê°œì›”")
                            message = f'âœ… í‰ê·  ì‹¤ê±°ë˜ê°€: {property_value_estimate:,}ë§Œì› (ìµœê·¼ {period_text}, {len(amounts)}ê±´ ë¶„ì„)'
                            yield f"data: {json.dumps({'step': 4, 'message': message, 'progress': 0.6}, ensure_ascii=False)}\n\n"
                            await asyncio.sleep(0.5)

            # registry_data ì—…ë°ì´íŠ¸
            if registry_data and property_value_estimate:
                from core.risk_engine import PropertyType, get_default_auction_rate

                contract_type = case.get('contract_type', 'ì „ì„¸')
                property_type = case.get('metadata', {}).get('property_type')
                sido = case.get('metadata', {}).get('sido')
                sigungu = case.get('metadata', {}).get('sigungu')
                auction_rate_override = case.get('metadata', {}).get('auction_rate_override')

                if contract_type in ["ì „ì„¸", "ì›”ì„¸"]:
                    auction_rate = 0.70
                    if auction_rate_override is not None:
                        auction_rate = auction_rate_override
                    elif property_type and sido and sigungu:
                        auction_rate = get_default_auction_rate(
                            property_type=PropertyType(property_type),
                            sido=sido,
                            sigungu=sigungu
                        )

                    registry_data.property_value = int(property_value_estimate * auction_rate)
                    message = f'âœ… ë¬¼ê±´ ê°€ì¹˜ ê³„ì‚°: {property_value_estimate:,}ë§Œì› Ã— {auction_rate * 100:.0f}% = {registry_data.property_value:,}ë§Œì›'
                    yield f"data: {json.dumps({'step': 4, 'message': message, 'progress': 0.65}, ensure_ascii=False)}\n\n"
                else:
                    registry_data.property_value = property_value_estimate

            # 5ë‹¨ê³„: ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚°
            yield f"data: {json.dumps({'step': 5, 'message': 'ğŸ“Š ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚° ì¤‘...', 'progress': 0.7}, ensure_ascii=False)}\n\n"

            from core.risk_engine import analyze_risks, ContractData, PropertyType

            contract_type = case.get('contract_type', 'ì „ì„¸')
            property_type = case.get('metadata', {}).get('property_type')
            sido = case.get('metadata', {}).get('sido')
            sigungu = case.get('metadata', {}).get('sigungu')
            auction_rate_override = case.get('metadata', {}).get('auction_rate_override')

            contract_data = ContractData(
                contract_type=contract_type,
                deposit=case.get('metadata', {}).get('deposit'),
                price=case.get('metadata', {}).get('price'),
                property_address=case.get('property_address') if contract_type == 'ë§¤ë§¤' else None,
                property_type=PropertyType(property_type) if property_type else None,
                sido=sido,
                sigungu=sigungu,
                auction_rate_override=auction_rate_override,
            )

            risk_result = None
            if contract_type == 'ë§¤ë§¤':
                from core.risk_engine import MarketData
                market_data = MarketData(
                    avg_trade_price=property_value_estimate,
                    recent_trades=[],
                    avg_price_per_pyeong=None,
                ) if property_value_estimate else None

                risk_result = analyze_risks(contract_data, registry=registry_data, market=market_data, property_value=None)
            else:
                if registry_data:
                    risk_result = analyze_risks(contract_data, registry_data)

            if risk_result:
                risk_message = f"âœ… ë¦¬ìŠ¤í¬ ë¶„ì„ ì™„ë£Œ\n"
                risk_message += f"   ğŸ“Š ì´ì : {risk_result.risk_score.total_score:.1f}ì \n"
                risk_message += f"   ğŸ¯ ìœ„í—˜ ë“±ê¸‰: {risk_result.risk_score.risk_level}\n"

                if risk_result.risk_score.jeonse_ratio:
                    risk_message += f"   ğŸ’° ì „ì„¸ê°€ìœ¨: {risk_result.risk_score.jeonse_ratio:.1f}%\n"

                if risk_result.risk_score.mortgage_ratio:
                    risk_message += f"   ğŸ¦ ê·¼ì €ë‹¹ ë¹„ìœ¨: {risk_result.risk_score.mortgage_ratio:.1f}%\n"

                yield f"data: {json.dumps({'step': 5, 'message': risk_message, 'progress': 0.75, 'risk_score': risk_result.risk_score.dict()}, ensure_ascii=False)}\n\n"
                await asyncio.sleep(1.0)

            # 6ë‹¨ê³„: ë“€ì–¼ LLM ìˆœì°¨ ìŠ¤íŠ¸ë¦¬ë° (GPT-4o-mini â†’ Claude Sonnet ê²€ì¦)
            # merge_dual_streams()ê°€ ë‹¨ê³„ë³„ ë©”ì‹œì§€ë¥¼ ìë™ìœ¼ë¡œ ì „ì†¡:
            #   1) GPT-4o-mini ì´ˆì•ˆ ìƒì„± (ğŸ“ ì´ˆì•ˆ ìƒì„± ì¤‘... â†’ âœ… ì´ˆì•ˆ ì™„ë£Œ)
            #   2) 3ì´ˆ ëŒ€ê¸° í›„ Claude Sonnet ê²€ì¦ ì‹œì‘ (ğŸ” ê²€ì¦ ì‹œì‘... â†’ ğŸ” ê²€ì¦ ì¤‘... â†’ âœ… ê²€ì¦ ì™„ë£Œ)
            # merge_dual_streams()ê°€ ë‹¨ê³„ë³„ ë©”ì‹œì§€ë¥¼ ìë™ìœ¼ë¡œ ì „ì†¡:
            #   1) GPT-4o-mini ì´ˆì•ˆ ìƒì„± (ğŸ“ ì´ˆì•ˆ ìƒì„± ì¤‘... â†’ âœ… ì´ˆì•ˆ ì™„ë£Œ)
            #   2) 3ì´ˆ ëŒ€ê¸° í›„ Claude Sonnet ê²€ì¦ ì‹œì‘ (ğŸ” ê²€ì¦ ì‹œì‘... â†’ ğŸ” ê²€ì¦ ì¤‘... â†’ âœ… ê²€ì¦ ì™„ë£Œ)

            from core.report_generator import build_risk_features_from_registry, build_llm_prompt
            from langchain_openai import ChatOpenAI
            from langchain_anthropic import ChatAnthropic
            from langchain_core.messages import HumanMessage, SystemMessage

            # í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
            risk_features = None
            if artifact_response.data and registry_url and registry_doc:
                risk_features = build_risk_features_from_registry(
                    registry_doc=registry_doc,
                    contract_deposit=case.get('metadata', {}).get('deposit'),
                    contract_price=case.get('metadata', {}).get('price'),
                    property_value=registry_data.property_value if registry_data else None
                )

            llm_prompt = None
            if risk_features:
                llm_prompt = build_llm_prompt(
                    risk_features=risk_features,
                    contract_type=contract_type,
                    contract_deposit=case.get('metadata', {}).get('deposit'),
                    contract_price=case.get('metadata', {}).get('price'),
                    monthly_rent=case.get('metadata', {}).get('monthly_rent')
                )
            else:
                llm_prompt = f"""# ë¶€ë™ì‚° ê³„ì•½ ë¶„ì„ ìš”ì²­

**ì£¼ì†Œ**: {case['property_address']}
**ê³„ì•½ ìœ í˜•**: {contract_type}

**ë“±ê¸°ë¶€ ì •ë³´**: ì—†ìŒ

ìœ„ ì •ë³´ë§Œìœ¼ë¡œ ê°„ë‹¨í•œ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”."""

            # ===========================
            # ë³‘ë ¬ ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜ ì •ì˜
            # ===========================
            async def stream_gpt_draft():
                """GPT-4o-mini ì´ˆì•ˆ ìƒì„± ìŠ¤íŠ¸ë¦¬ë°"""
                llm_draft = ChatOpenAI(model="gpt-4o-mini", temperature=0.3, max_tokens=4096, streaming=True)
                draft_content = ""
                chunk_count = 0

                try:
                    async for chunk in llm_draft.astream([HumanMessage(content=llm_prompt)]):
                        if hasattr(chunk, 'content') and chunk.content:
                            draft_content += chunk.content
                            chunk_count += 1

                            # ì´ë²¤íŠ¸ ì „ì†¡ (phase='draft', model='gpt-4o-mini')
                            if chunk_count % 5 == 0:  # ë” ìì£¼ ì—…ë°ì´íŠ¸
                                yield {
                                    'phase': 'draft',
                                    'model': 'gpt-4o-mini',
                                    'content': chunk.content,
                                    'total_length': len(draft_content),
                                    'done': False
                                }

                    # ì™„ë£Œ ì´ë²¤íŠ¸
                    yield {
                        'phase': 'draft',
                        'model': 'gpt-4o-mini',
                        'content': '',
                        'total_length': len(draft_content),
                        'done': True,
                        'final_content': draft_content
                    }

                except Exception as e:
                    logger.error(f"GPT ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
                    yield {
                        'phase': 'draft',
                        'model': 'gpt-4o-mini',
                        'error': str(e),
                        'done': True
                    }

            async def stream_claude_validation(draft_content):
                """Claude Sonnet ê²€ì¦ ìŠ¤íŠ¸ë¦¬ë° (ì´ˆì•ˆ ê¸°ë°˜)"""
                # ì´ˆì•ˆì´ ì¶©ë¶„íˆ ìƒì„±ë  ë•Œê¹Œì§€ ëŒ€ê¸°
                await asyncio.sleep(3)

                judge_prompt = build_judge_prompt(draft_content)

                llm_judge = ChatAnthropic(model="claude-3-5-sonnet-latest", temperature=0.1, max_tokens=4096, streaming=True)
                validation_content = ""
                chunk_count = 0

                try:
                    async for chunk in llm_judge.astream([HumanMessage(content=judge_prompt)]):
                        if hasattr(chunk, 'content') and chunk.content:
                            validation_content += chunk.content
                            chunk_count += 1

                            # ì´ë²¤íŠ¸ ì „ì†¡ (phase='validation', model='claude-3-5-sonnet')
                            if chunk_count % 5 == 0:
                                yield {
                                    'phase': 'validation',
                                    'model': 'claude-3-5-sonnet',
                                    'content': chunk.content,
                                    'total_length': len(validation_content),
                                    'done': False
                                }

                    # ì™„ë£Œ ì´ë²¤íŠ¸
                    yield {
                        'phase': 'validation',
                        'model': 'claude-3-5-sonnet',
                        'content': '',
                        'total_length': len(validation_content),
                        'done': True,
                        'final_content': validation_content
                    }

                except Exception as e:
                    msg = str(e)
                    # Fallback to Haiku
                    if "NotFound" in msg or "not_found_error" in msg or "model:" in msg:
                        logger.warning("Claude Sonnet ì‹¤íŒ¨, Haikuë¡œ í´ë°±")

                        llm_haiku = ChatAnthropic(model="claude-3-5-haiku-latest", temperature=0.1, max_tokens=4096, streaming=True)
                        validation_content = ""

                        async for chunk in llm_haiku.astream([HumanMessage(content=judge_prompt)]):
                            if hasattr(chunk, 'content') and chunk.content:
                                validation_content += chunk.content

                                if chunk_count % 5 == 0:
                                    yield {
                                        'phase': 'validation',
                                        'model': 'claude-3-5-haiku',
                                        'content': chunk.content,
                                        'total_length': len(validation_content),
                                        'done': False
                                    }

                        yield {
                            'phase': 'validation',
                            'model': 'claude-3-5-haiku',
                            'done': True,
                            'final_content': validation_content
                        }
                    else:
                        logger.error(f"Claude ê²€ì¦ ì‹¤íŒ¨: {e}")
                        yield {
                            'phase': 'validation',
                            'model': 'claude-3-5-sonnet',
                            'error': str(e),
                            'done': True
                        }

            # ===========================
            # ë³‘ë ¬ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
            # ===========================
            async for event in merge_dual_streams(
                draft_generator=stream_gpt_draft(),
                validation_generator_factory=stream_claude_validation,
                step_base=6.0,
                progress_base=0.78
            ):
                if isinstance(event, str):
                    # SSE ì´ë²¤íŠ¸ ì „ë‹¬
                    yield event
                else:
                    # ìµœì¢… ê²°ê³¼ (draft_content, validation_content, last_validation_event)
                    draft_content, validation_content, last_validation_event = event

            # ===========================
            # ì¶©ëŒ ê°ì§€ ë° ìµœì¢… ë‹µë³€ ìƒì„±
            # ===========================
            conflicts = []
            if "ìˆ˜ì • í•„ìš”" in validation_content:
                conflicts.append("Claudeê°€ ì´ˆì•ˆì— ìˆ˜ì •ì´ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨í–ˆìŠµë‹ˆë‹¤.")
            if "ì¶”ê°€ í•„ìš”" in validation_content:
                conflicts.append("Claudeê°€ ëˆ„ë½ëœ í•­ëª©ì´ ìˆë‹¤ê³  íŒë‹¨í–ˆìŠµë‹ˆë‹¤.")

            if len(conflicts) == 0:
                # ë¶ˆì¼ì¹˜ ì—†ìŒ â†’ ì´ˆì•ˆ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                final_answer = draft_content
                confidence = 0.95
            else:
                # ë¶ˆì¼ì¹˜ ìˆìŒ â†’ ê²€ì¦ ê²°ê³¼ í¬í•¨
                final_answer = f"""### ChatGPT ì´ˆì•ˆ
{draft_content}

### Claude ê²€ì¦ ì˜ê²¬
{validation_content}

âš ï¸ ë‘ ëª¨ë¸ ê°„ ê²¬í•´ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤. ìµœì¢… íŒë‹¨ì€ ë²•ë¬´ì‚¬ ë˜ëŠ” ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì„¸ìš”.
"""
                confidence = 0.75

            # ë“€ì–¼ ë¶„ì„ ì™„ë£Œ
            message = f'âœ… ë“€ì–¼ AI ë¶„ì„ ì™„ë£Œ (ì‹ ë¢°ë„: {confidence*100:.0f}%)'
            data = {
                'step': 6.9,
                'message': message,
                'progress': 0.9,
                'confidence': confidence,
                'conflicts': conflicts,
                'draft_length': len(draft_content),
                'validation_length': len(validation_content)
            }
            yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
            await asyncio.sleep(0.5)

            # 7ë‹¨ê³„: ë¦¬í¬íŠ¸ ì €ì¥
            yield f"data: {json.dumps({'step': 7, 'message': 'ğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥ ì¤‘...', 'progress': 0.95}, ensure_ascii=False)}\n\n"

            market_data = None
            report_response = supabase.table("v2_reports").insert({
                "case_id": case_id,
                "user_id": case['user_id'],
                "content": final_answer,
                "risk_score": risk_result.risk_score.dict() if risk_result else {},
                "registry_data": registry_doc_masked,
                "report_data": {
                    "summary": final_answer,
                    "risk": risk_result.risk_score.dict() if risk_result else {},
                    "registry": registry_doc_masked,
                    "market": market_data.dict() if (contract_type == 'ë§¤ë§¤' and market_data) else None
                },
                "metadata": {
                    "dual_analysis": True,
                    "draft_model": "gpt-4o-mini",
                    "validation_model": last_validation_event.get('model', 'claude-3-5-sonnet') if last_validation_event else None,
                    "confidence": confidence,
                    "conflicts": conflicts,
                    "draft_length": len(draft_content),
                    "validation_length": len(validation_content),
                    "analysis_method": "parallel_streaming",
                }
            }).execute()

            if not report_response.data:
                yield f"data: {json.dumps({'error': 'ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨'}, ensure_ascii=False)}\n\n"
                return

            report_id = report_response.data[0]['id']
            logger.info(f"âœ… [SSE] ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: case_id={case_id}, user_id={case['user_id']}, report_id={report_id}")

            # 8ë‹¨ê³„: ìƒíƒœ ì „í™˜
            supabase.table("v2_cases").update({
                "current_state": "report",
                "updated_at": datetime.utcnow().isoformat(),
            }).eq("id", case_id).execute()

            # âœ… ê²€ì¦ ë‹¨ê³„ ì¶”ê°€ (SSE_REPORT_DEBUG.md ë°©ì•ˆ 1)
            # 8-1: v2_reports ì¬í™•ì¸ (Supabase ë¦¬í”Œë¦¬ì¼€ì´ì…˜ ì§€ì—° ï¿½ï¿½ì§€)
            verify_report = supabase.table("v2_reports") \
                .select("id") \
                .eq("id", report_id) \
                .execute()

            if not verify_report.data:
                logger.error(f"âŒ [SSE ê²€ì¦ ì‹¤íŒ¨] ë¦¬í¬íŠ¸ ê²€ì¦ ì‹¤íŒ¨: report_id={report_id}")
                yield f"data: {json.dumps({'error': 'ë¦¬í¬íŠ¸ ì €ì¥ ê²€ì¦ ì‹¤íŒ¨. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'}, ensure_ascii=False)}\n\n"
                return

            # 8-2: v2_cases current_state ì¬í™•ì¸
            verify_case = supabase.table("v2_cases") \
                .select("current_state") \
                .eq("id", case_id) \
                .execute()

            if not verify_case.data or verify_case.data[0]['current_state'] != 'report':
                current = verify_case.data[0]['current_state'] if verify_case.data else 'unknown'
                logger.error(f"âŒ [SSE ê²€ì¦ ì‹¤íŒ¨] ì¼€ì´ìŠ¤ ìƒíƒœ ê²€ì¦ ì‹¤íŒ¨: case_id={case_id}, current_state={current}")
                yield f"data: {json.dumps({'error': 'ì¼€ì´ìŠ¤ ìƒíƒœ ì „í™˜ ì‹¤íŒ¨. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'}, ensure_ascii=False)}\n\n"
                return

            logger.info(f"âœ… [SSE ê²€ì¦ í†µê³¼] ë¦¬í¬íŠ¸ ë° ìƒíƒœ ì „í™˜ í™•ì¸ ì™„ë£Œ")

            # ì™„ë£Œ (ê²€ì¦ í†µê³¼ í›„ì—ë§Œ ì „ì†¡)
            yield f"data: {json.dumps({'step': 8, 'message': 'âœ… ë¶„ì„ ì™„ë£Œ!', 'progress': 1.0, 'report_id': report_id, 'done': True}, ensure_ascii=False)}\n\n"

        except Exception as e:
            logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
            yield f"data: {json.dumps({'error': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'}, ensure_ascii=False)}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")


# Alias: POST /analyze (guide compatibility)
@router.post("", response_model=AnalysisStatusResponse)
async def analyze_alias(
    request: StartAnalysisRequest,
    user: dict = Depends(get_current_user)
):
    """
    Guide í˜¸í™˜ìš© ë³„ì¹­ ì—”ë“œí¬ì¸íŠ¸.

    - POST /analyze â†’ ë‚´ë¶€ì ìœ¼ë¡œ /analyze/startì™€ ë™ì¼ ë™ì‘
    """
    return await start_analysis(request, user)


@router.get("/status/{case_id}", response_model=AnalysisStatusResponse)
async def get_analysis_status(
    case_id: str,
    user: dict = Depends(get_current_user)
):
    """
    ë¶„ì„ ìƒíƒœ ì¡°íšŒ

    - í˜„ì¬ ì¼€ì´ìŠ¤ ìƒíƒœì™€ ì§„í–‰ë¥  ë°˜í™˜
    """
    supabase = get_supabase_client()

    case_response = supabase.table("v2_cases") \
        .select("*") \
        .eq("id", case_id) \
        .eq("user_id", user["sub"]) \
        .execute()

    if not case_response.data:
        raise HTTPException(404, "Case not found")

    case = case_response.data[0]
    current_state = case["current_state"]

    messages = {
        "init": "ì‹œì‘í•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬ ì§„í–‰í•˜ì„¸ìš”.",
        "address_pick": "ë¶€ë™ì‚° ì£¼ì†Œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
        "contract_type": "ê³„ì•½ ìœ í˜•ì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
        "registry_choice": "ë“±ê¸°ë¶€ ë°œê¸‰ ë˜ëŠ” ì—…ë¡œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.",
        "registry_ready": "ë“±ê¸°ë¶€ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "parse_enrich": "ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...",
        "report": "ë¦¬í¬íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.",
    }

    return AnalysisStatusResponse(
        case_id=case_id,
        current_state=current_state,
        progress=STATE_PROGRESS.get(current_state, 0.0),
        message=messages.get(current_state, "ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœì…ë‹ˆë‹¤."),
    )


@router.post("/transition/{case_id}", response_model=AnalysisStatusResponse)
async def transition_state(
    case_id: str,
    target_state: str,
    user: dict = Depends(get_current_user)
):
    """
    ìƒíƒœ ì „í™˜ (ë””ë²„ê¹…/í…ŒìŠ¤íŠ¸ìš©)

    - ìˆ˜ë™ìœ¼ë¡œ ì¼€ì´ìŠ¤ ìƒíƒœë¥¼ ì „í™˜
    - í”„ë¡œë•ì…˜ì—ì„œëŠ” ìë™ ì „í™˜ ì‚¬ìš© ê¶Œì¥
    """
    supabase = get_supabase_client()

    # ìœ íš¨í•œ ìƒíƒœì¸ì§€ í™•ì¸
    valid_states = list(STATE_TRANSITIONS.keys()) + ["report"]
    if target_state not in valid_states:
        raise HTTPException(400, f"Invalid state: {target_state}")

    # ì¼€ì´ìŠ¤ ì—…ë°ì´íŠ¸
    update_response = supabase.table("v2_cases") \
        .update({
            "current_state": target_state,
            "updated_at": datetime.utcnow().isoformat(),
        }) \
        .eq("id", case_id) \
        .eq("user_id", user["sub"]) \
        .execute()

    if not update_response.data:
        raise HTTPException(404, "Case not found or update failed")

    return AnalysisStatusResponse(
        case_id=case_id,
        current_state=target_state,
        progress=STATE_PROGRESS.get(target_state, 0.0),
        message=f"ìƒíƒœê°€ '{target_state}'ë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
    )


@router.get("/result/{case_id}", response_model=AnalysisResultResponse)
async def get_analysis_result(
    case_id: str,
    user: dict = Depends(get_current_user)
):
    """
    ë¶„ì„ ê²°ê³¼ ì¡°íšŒ

    - ì™„ë£Œëœ ë¶„ì„ì˜ ë¦¬í¬íŠ¸ ë°˜í™˜
    - TODO: Phase 3ì—ì„œ ë¦¬í¬íŠ¸ ì‹œìŠ¤í…œ êµ¬í˜„
    """
    supabase = get_supabase_client()

    # ì¼€ì´ìŠ¤ ì¡°íšŒ
    case_response = supabase.table("v2_cases") \
        .select("*") \
        .eq("id", case_id) \
        .eq("user_id", user["sub"]) \
        .execute()

    if not case_response.data:
        raise HTTPException(404, "Case not found")

    case = case_response.data[0]

    # ë¶„ì„ ì™„ë£Œ ì—¬ë¶€ í™•ì¸
    if case["current_state"] not in ["report", "completed"]:
        raise HTTPException(
            400,
            f"Analysis not completed. Current state: {case['current_state']}"
        )

    # TODO: v2_reports í…Œì´ë¸”ì—ì„œ ë¦¬í¬íŠ¸ ì¡°íšŒ
    # report_response = supabase.table("v2_reports") \
    #     .select("*") \
    #     .eq("case_id", case_id) \
    #     .execute()

    # ì„ì‹œ ì‘ë‹µ (Phase 3ì—ì„œ ì‹¤ì œ ë¦¬í¬íŠ¸ ë°˜í™˜)
    return AnalysisResultResponse(
        case_id=case_id,
        report_id=None,
        risks=None,
        recommendations=None,
        summary="ë¶„ì„ ê²°ê³¼ëŠ” Phase 3ì—ì„œ êµ¬í˜„ë©ë‹ˆë‹¤.",
    )


@router.post("/crosscheck", response_model=CrosscheckResponse)
async def crosscheck_draft(
    request: CrosscheckRequest,
    user: dict = Depends(get_current_user)
):
    """
    Guide í˜¸í™˜ìš©: Claudeë¡œ ì´ˆì•ˆì„ êµì°¨ê²€ì¦.
    """
    judge_prompt = build_judge_prompt(request.draft)
    llm = ChatAnthropic(model="claude-3-5-sonnet-latest", temperature=0.1, max_tokens=4096)
    msgs = [
        SystemMessage(content=judge_prompt),
        HumanMessage(content="ê²€ï¿½ï¿½ì„ ìˆ˜í–‰í•˜ì„¸ìš”."),
    ]
    resp = llm.invoke(msgs)
    return CrosscheckResponse(validation=resp.content)


@router.get("/audit-logs/{case_id}", response_model=AuditLogsResponse)
async def get_audit_logs(
    case_id: str,
    severity: Optional[str] = None,
    category: Optional[str] = None,
    limit: int = 50,
    user: dict = Depends(get_current_user)
):
    """
    ì¼€ì´ìŠ¤ ê°ì‚¬ ë¡œê·¸ ì¡°íšŒ

    - íŒŒì‹± ì—ëŸ¬, ê²½ê³ , ì„±ê³µ ì´ë²¤íŠ¸ ë“±ì„ ì¡°íšŒ
    - severity í•„í„°: error, warning, info ë“±
    - category í•„í„°: parsing, registry, llm ë“±

    Args:
        case_id: ì¼€ì´ìŠ¤ UUID
        severity: ì‹¬ê°ë„ í•„í„° (ì„ íƒ)
        category: ì¹´í…Œê³ ë¦¬ í•„í„° (ì„ íƒ)
        limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 50)
        user: í˜„ì¬ ì‚¬ìš©ì

    Returns:
        ê°ì‚¬ ë¡œê·¸ ëª©ë¡
    """
    supabase = get_supabase_client(service_role=True)

    # ì¼€ì´ìŠ¤ ê¶Œí•œ í™•ì¸
    case_response = supabase.table("v2_cases") \
        .select("id") \
        .eq("id", case_id) \
        .eq("user_id", user["sub"]) \
        .execute()

    if not case_response.data:
        raise HTTPException(404, "Case not found")

    # ê°ì‚¬ ë¡œê·¸ ì¡°íšŒ
    query = supabase.table("v2_audit_logs") \
        .select("*") \
        .eq("case_id", case_id) \
        .order("created_at", desc=True) \
        .limit(limit)

    # í•„í„° ì ìš©
    if severity:
        query = query.eq("severity", severity)

    if category:
        query = query.eq("event_category", category)

    logs_response = query.execute()

    # ì‘ë‹µ ë³€í™˜
    logs = [
        AuditLogEntry(
            id=log["id"],
            event_type=log["event_type"],
            event_category=log["event_category"],
            message=log["message"],
            severity=log["severity"],
            created_at=log["created_at"],
            metadata=log.get("metadata"),
        )
        for log in logs_response.data
    ]

    return AuditLogsResponse(
        case_id=case_id,
        total_count=len(logs),
        logs=logs,
    )


# ===========================
# í—¬í¼ í•¨ìˆ˜ (í–¥í›„ êµ¬í˜„)
# ===========================

async def execute_analysis_pipeline(case_id: str):
    """
    ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    1. ì¼€ì´ìŠ¤ ë°ì´í„° ì¡°íšŒ (ì£¼ì†Œ, ê³„ì•½ì„œ, ë“±ê¸°ë¶€)
    2. ë“±ê¸°ë¶€ íŒŒì‹± ë° êµ¬ì¡°í™”
    3. ê³µê³µ ë°ì´í„° ìˆ˜ì§‘
    4. ë¦¬ìŠ¤í¬ ì—”ì§„ ì‹¤í–‰ â†’ ìœ„í—˜ ì ìˆ˜ ê³„ì‚°
    5. LLM ë“€ì–¼ ì‹œìŠ¤í…œ ì‹¤í–‰ â†’ ì´ˆì•ˆ ìƒì„± + ê²€ì¦
    6. ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ì¥
    7. ìƒíƒœ ì „í™˜: analysis â†’ report â†’ completed
    """
    from core.supabase_client import get_supabase_client
    from ingest.registry_parser import parse_registry_from_url
    from core.public_data_api import AptTradeAPIClient, LegalDongCodeAPIClient
    from core.risk_engine import analyze_risks, ContractData, RegistryData
    from core.llm_router import dual_model_analyze
    from core.settings import settings
    import httpx
    from datetime import datetime

    # Service Role Key ì‚¬ìš© (RLS ìš°íšŒ)
    supabase = get_supabase_client(service_role=True)
    logger.info(f"ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘: case_id={case_id}")

    try:
        # 1ï¸âƒ£ ì¼€ì´ìŠ¤ ë°ì´í„° ì¡°íšŒ
        case_response = supabase.table("v2_cases").select("*").eq("id", case_id).execute()
        if not case_response.data:
            raise HTTPException(404, f"Case not found: {case_id}")

        case = case_response.data[0]
        logger.info(f"ì¼€ì´ìŠ¤ ì¡°íšŒ ì™„ë£Œ: {case['property_address']}")

        # 2ï¸âƒ£ ë“±ê¸°ë¶€ íŒŒì‹± (v2_artifactsì—ì„œ registry_file_url ì¡°íšŒ)
        artifact_response = supabase.table("v2_artifacts") \
            .select("*") \
            .eq("case_id", case_id) \
            .eq("artifact_type", "registry_pdf") \
            .execute()

        registry_data = None
        registry_doc_masked = None  # ìœ ì €ì—ê²Œ ë³´ì—¬ì¤„ ë§ˆìŠ¤í‚¹ëœ ë°ì´í„°

        if artifact_response.data:
            # ë™ì  Signed URL ìƒì„± (1ì‹œê°„ ë§Œë£Œ)
            file_path = artifact_response.data[0].get("file_path")
            if file_path:
                bucket, path = file_path.split("/", 1)
                registry_url = await supabase_storage.get_signed_url(bucket, path, expires_in=3600)
                logger.info(f"ë“±ê¸°ë¶€ íŒŒì‹± ì‹œì‘: {file_path} (Signed URL ìƒì„±)")
                # ê°ì‚¬ ë¡œê·¸ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                registry_doc = await parse_registry_from_url(registry_url, case_id=case_id, user_id=case['user_id'])

                # RegistryData ëª¨ë¸ë¡œ ë³€í™˜ (ë‚´ë¶€ ë¶„ì„ìš© - ì›ë³¸ ì‚¬ìš©)
                registry_data = RegistryData(
                    property_value=None,  # ê³µê³µ ë°ì´í„°ì—ì„œ ì¶”ì •
                    mortgage_total=sum([m.amount or 0 for m in registry_doc.mortgages]),
                    seizure_exists=any(s.type == "ì••ë¥˜" for s in registry_doc.seizures),
                    provisional_attachment_exists=any(s.type == "ê°€ì••ë¥˜" for s in registry_doc.seizures),
                    ownership_disputes=False  # TODO: ì†Œìœ ê¶Œ ë¶„ìŸ ê°ì§€ ë¡œì§
                )

                # ë§ˆìŠ¤í‚¹ëœ ë²„ì „ (ìœ ì € í‘œì‹œìš©)
                registry_doc_masked = registry_doc.to_masked_dict()

                logger.info(f"ë“±ê¸°ë¶€ íŒŒì‹± ì™„ë£Œ: ê·¼ì €ë‹¹ {registry_data.mortgage_total}ë§Œì›")
                logger.info(f"ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ ì™„ë£Œ: ì†Œìœ ì={registry_doc_masked['owner']['name'] if registry_doc_masked.get('owner') else None}")

        # 3ï¸âƒ£ ê³µê³µ ë°ì´í„° ìˆ˜ì§‘ (ì‹¤ê±°ë˜ê°€ë¡œ property_value ì¶”ì •)

        # í—¬í¼ í•¨ìˆ˜: ì´ì „ ì›” ê³„ì‚° (YYYYMM í˜•ì‹)
        def get_previous_month(year: int, month: int, months_back: int = 1) -> str:
            """
            í˜„ì¬ ë…„ì›”ë¡œë¶€í„° Nê°œì›” ì´ì „ ì›” ê³„ì‚°

            Args:
                year: ì‹œì‘ ë…„ë„
                month: ì‹œì‘ ì›”
                months_back: ì´ì „ ê°œì›” ìˆ˜ (ê¸°ë³¸ê°’: 1)

            Returns:
                YYYYMM í˜•ì‹ ë¬¸ìì—´
            """
            from datetime import datetime, timedelta
            from dateutil.relativedelta import relativedelta

            current_date = datetime(year, month, 1)
            target_date = current_date - relativedelta(months=months_back)
            return f"{target_date.year}{target_date.month:02d}"

        # í—¬í¼ í•¨ìˆ˜: ìµœëŒ“ê°’/ìµœì†Ÿê°’ ì œì™¸ í‰ê·  ê³„ì‚°
        def calculate_average_exclude_outliers(amounts: list[int]) -> Optional[int]:
            """
            ê¸ˆì•¡ ë¦¬ìŠ¤íŠ¸ì—ì„œ ìµœëŒ“ê°’/ìµœì†Ÿê°’ì„ ì œì™¸í•œ í‰ê·  ê³„ì‚°

            Args:
                amounts: ê¸ˆì•¡ ë¦¬ìŠ¤íŠ¸ (ë§Œì› ë‹¨ìœ„)

            Returns:
                í‰ê· ê°’ (ë§Œì› ë‹¨ìœ„) ë˜ëŠ” None (ë°ì´í„° ë¶€ì¡± ì‹œ)
            """
            if len(amounts) <= 2:
                # ë°ì´í„°ê°€ 2ê°œ ì´í•˜ë©´ ë‹¨ìˆœ í‰ê· 
                return sum(amounts) // len(amounts) if amounts else None

            # ìµœëŒ“ê°’/ìµœì†Ÿê°’ ì œì™¸
            sorted_amounts = sorted(amounts)
            filtered_amounts = sorted_amounts[1:-1]  # ì²« ë²ˆì§¸(ìµœì†Œ)ì™€ ë§ˆì§€ë§‰(ìµœëŒ€) ì œì™¸

            if not filtered_amounts:
                return None

            return sum(filtered_amounts) // len(filtered_amounts)

        async with httpx.AsyncClient() as client:
            # ë²•ì •ë™ ì½”ë“œ ì¡°íšŒ
            legal_dong_client = LegalDongCodeAPIClient(
                api_key=settings.public_data_api_key,
                client=client
            )
            legal_dong_result = await legal_dong_client.get_legal_dong_code(
                keyword=case['property_address']
            )

            lawd_cd = None
            if legal_dong_result['body']['items']:
                lawd_cd = legal_dong_result['body']['items'][0]['lawd5']
                logger.info(f"ë²•ì •ë™ì½”ë“œ: {lawd_cd}")

            # ì‹¤ê±°ë˜ê°€ ì¡°íšŒ
            property_value_estimate = None  # ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ ê¸°ë°˜ (3ê°œì›”, ìµœëŒ€/ìµœì†Œ ì œì™¸, 70% ë‚™ì°°ê°€ìœ¨)
            jeonse_market_average = None  # ì „ì„¸ ì‹¤ê±°ë˜ê°€ ê¸°ë°˜ (6ê°œì›”, 100% ì‹œì¥ê°€)
            recent_transactions = []

            if lawd_cd:
                now = datetime.now()
                contract_type = case.get('contract_type', 'ì „ì„¸')

                # ============================
                # ì „ì„¸/ì›”ì„¸ ê³„ì•½: ë“€ì–¼ API í˜¸ì¶œ
                # ============================
                if contract_type in ["ì „ì„¸", "ì›”ì„¸"]:
                    logger.info(f"[ë“€ì–¼ API] {contract_type} ê³„ì•½ - ì „ì„¸ ì‹¤ê±°ë˜ê°€(6ê°œì›”) + ë§¤ë§¤ ì‹¤ê±°ë˜ê°€(3ê°œì›”) ì¡°íšŒ")

                    # (1) ì „ì„¸ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ (6ê°œì›”, 100%)
                    from core.public_data_api import AptRentAPIClient

                    apt_rent_client = AptRentAPIClient(
                        api_key=settings.public_data_api_key,
                        client=client
                    )

                    jeonse_amounts = []
                    for months_back in range(6):  # ìµœê·¼ 6ê°œì›”
                        deal_ymd = get_previous_month(now.year, now.month, months_back)

                        try:
                            rent_result = await apt_rent_client.get_apt_rent_transactions(
                                lawd_cd=lawd_cd,
                                deal_ymd=deal_ymd
                            )

                            if rent_result['body']['items']:
                                for item in rent_result['body']['items']:
                                    # ì „ì„¸ë§Œ í•„í„°ë§ (ì›”ì„¸ ì œì™¸)
                                    if item.get('deposit') and not item.get('monthlyRent'):
                                        jeonse_amounts.append(item['deposit'])
                        except Exception as e:
                            logger.warning(f"ì „ì„¸ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ ì‹¤íŒ¨ ({deal_ymd}): {e}")
                            continue

                    # ì „ì„¸ ì‹œì¥ í‰ê·  ê³„ì‚° (ë‹¨ìˆœ í‰ê· )
                    if jeonse_amounts:
                        jeonse_market_average = sum(jeonse_amounts) // len(jeonse_amounts)
                        logger.info(f"âœ… ì „ì„¸ ì‹¤ê±°ë˜ê°€ í‰ê·  (6ê°œì›”): {jeonse_market_average:,}ë§Œì› ({len(jeonse_amounts)}ê±´ ë¶„ì„)")
                    else:
                        logger.warning("âš ï¸ ì „ì„¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ì—†ìŒ (6ê°œì›”)")

                    # (2) ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ (ë™ì  ê¸°ê°„ í™•ëŒ€: 3ê°œì›” â†’ 6ê°œì›” â†’ 12ê°œì›”)
                    apt_trade_client = AptTradeAPIClient(
                        api_key=settings.public_data_api_key,
                        client=client
                    )

                    sale_amounts = []
                    query_period = "3ê°œì›”"

                    # Step 1: 3ê°œì›” ì¡°íšŒ
                    for months_back in range(3):
                        deal_ymd = get_previous_month(now.year, now.month, months_back)

                        try:
                            trade_result = await apt_trade_client.get_apt_trades(
                                lawd_cd=lawd_cd,
                                deal_ymd=deal_ymd
                            )

                            if trade_result['body']['items']:
                                recent_transactions.extend(trade_result['body']['items'])
                                for item in trade_result['body']['items']:
                                    if item.get('dealAmount'):
                                        sale_amounts.append(item['dealAmount'])
                        except Exception as e:
                            logger.warning(f"ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ ì‹¤íŒ¨ ({deal_ymd}): {e}")
                            continue

                    # Step 2: 3ê°œì›” ë°ì´í„° < 5ê°œ â†’ 6ê°œì›”ê¹Œì§€ í™•ëŒ€
                    if len(sale_amounts) < 5:
                        logger.info(f"ğŸ“Š ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ {len(sale_amounts)}ê±´ (< 5ê±´) â†’ 6ê°œì›”ê¹Œì§€ í™•ëŒ€ ì¡°íšŒ")
                        query_period = "6ê°œì›”"

                        for months_back in range(3, 6):
                            deal_ymd = get_previous_month(now.year, now.month, months_back)

                            try:
                                trade_result = await apt_trade_client.get_apt_trades(
                                    lawd_cd=lawd_cd,
                                    deal_ymd=deal_ymd
                                )

                                if trade_result['body']['items']:
                                    recent_transactions.extend(trade_result['body']['items'])
                                    for item in trade_result['body']['items']:
                                        if item.get('dealAmount'):
                                            sale_amounts.append(item['dealAmount'])
                            except Exception as e:
                                logger.warning(f"ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ ì‹¤íŒ¨ ({deal_ymd}): {e}")
                                continue

                    # Step 3: 6ê°œì›” ë°ì´í„° < 10ê°œ â†’ 12ê°œì›”ê¹Œì§€ í™•ëŒ€
                    if len(sale_amounts) < 10:
                        logger.info(f"ğŸ“Š ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ {len(sale_amounts)}ê±´ (< 10ê±´) â†’ 12ê°œì›”ê¹Œì§€ í™•ëŒ€ ì¡°íšŒ")
                        query_period = "12ê°œì›”"

                        for months_back in range(6, 12):
                            deal_ymd = get_previous_month(now.year, now.month, months_back)

                            try:
                                trade_result = await apt_trade_client.get_apt_trades(
                                    lawd_cd=lawd_cd,
                                    deal_ymd=deal_ymd
                                )

                                if trade_result['body']['items']:
                                    recent_transactions.extend(trade_result['body']['items'])
                                    for item in trade_result['body']['items']:
                                        if item.get('dealAmount'):
                                            sale_amounts.append(item['dealAmount'])
                            except Exception as e:
                                logger.warning(f"ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ ì‹¤íŒ¨ ({deal_ymd}): {e}")
                                continue

                    # ë§¤ë§¤ í‰ê·  ê³„ì‚° (ìµœëŒ€/ìµœì†Œ ì œì™¸)
                    if sale_amounts:
                        filtered_average = calculate_average_exclude_outliers(sale_amounts)
                        if filtered_average:
                            property_value_estimate = filtered_average
                            analyzed_count = max(len(sale_amounts) - 2, len(sale_amounts))
                            logger.info(f"âœ… ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ í‰ê·  ({query_period}, ìµœëŒ€/ìµœì†Œ ì œì™¸): {property_value_estimate:,}ë§Œì› ({len(sale_amounts)}ê±´ ì¤‘ {analyzed_count}ê±´ ë¶„ì„)")
                        else:
                            logger.warning("âš ï¸ ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ í•„í„°ë§ í›„ ë°ì´í„° ë¶€ì¡±")
                    else:
                        logger.warning(f"âš ï¸ ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ì—†ìŒ ({query_period})")

                # ============================
                # ë§¤ë§¤ ê³„ì•½: ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ë§Œ ì¡°íšŒ (ë™ì  ê¸°ê°„ í™•ëŒ€: 3ê°œì›” â†’ 6ê°œì›” â†’ 12ê°œì›”)
                # ============================
                else:
                    logger.info(f"[ë‹¨ì¼ API] ë§¤ë§¤ ê³„ì•½ - ë§¤ë§¤ ì‹¤ê±°ë˜ê°€(ë™ì  ê¸°ê°„ í™•ëŒ€) ì¡°íšŒ")

                    apt_trade_client = AptTradeAPIClient(
                        api_key=settings.public_data_api_key,
                        client=client
                    )

                    amounts = []
                    query_period = "3ê°œì›”"

                    # Step 1: 3ê°œì›” ì¡°íšŒ
                    for months_back in range(3):
                        deal_ymd = get_previous_month(now.year, now.month, months_back)

                        try:
                            trade_result = await apt_trade_client.get_apt_trades(
                                lawd_cd=lawd_cd,
                                deal_ymd=deal_ymd
                            )

                            if trade_result['body']['items']:
                                recent_transactions.extend(trade_result['body']['items'])
                                for item in trade_result['body']['items']:
                                    if item.get('dealAmount'):
                                        amounts.append(item['dealAmount'])
                        except Exception as e:
                            logger.warning(f"ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ ì‹¤íŒ¨ ({deal_ymd}): {e}")
                            continue

                    # Step 2: 3ê°œì›” ë°ì´í„° < 5ê°œ â†’ 6ê°œì›”ê¹Œì§€ í™•ëŒ€
                    if len(amounts) < 5:
                        logger.info(f"ğŸ“Š ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ {len(amounts)}ê±´ (< 5ê±´) â†’ 6ê°œì›”ê¹Œì§€ í™•ëŒ€ ì¡°íšŒ")
                        query_period = "6ê°œì›”"

                        for months_back in range(3, 6):
                            deal_ymd = get_previous_month(now.year, now.month, months_back)

                            try:
                                trade_result = await apt_trade_client.get_apt_trades(
                                    lawd_cd=lawd_cd,
                                    deal_ymd=deal_ymd
                                )

                                if trade_result['body']['items']:
                                    recent_transactions.extend(trade_result['body']['items'])
                                    for item in trade_result['body']['items']:
                                        if item.get('dealAmount'):
                                            amounts.append(item['dealAmount'])
                            except Exception as e:
                                logger.warning(f"ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ ì‹¤íŒ¨ ({deal_ymd}): {e}")
                                continue

                    # Step 3: 6ê°œì›” ë°ì´í„° < 10ê°œ â†’ 12ê°œì›”ê¹Œì§€ í™•ëŒ€
                    if len(amounts) < 10:
                        logger.info(f"ğŸ“Š ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ {len(amounts)}ê±´ (< 10ê±´) â†’ 12ê°œì›”ê¹Œì§€ í™•ëŒ€ ì¡°íšŒ")
                        query_period = "12ê°œì›”"

                        for months_back in range(6, 12):
                            deal_ymd = get_previous_month(now.year, now.month, months_back)

                            try:
                                trade_result = await apt_trade_client.get_apt_trades(
                                    lawd_cd=lawd_cd,
                                    deal_ymd=deal_ymd
                                )

                                if trade_result['body']['items']:
                                    recent_transactions.extend(trade_result['body']['items'])
                                    for item in trade_result['body']['items']:
                                        if item.get('dealAmount'):
                                            amounts.append(item['dealAmount'])
                            except Exception as e:
                                logger.warning(f"ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ ì‹¤íŒ¨ ({deal_ymd}): {e}")
                                continue

                    if amounts:
                        property_value_estimate = sum(amounts) // len(amounts)
                        logger.info(f"âœ… ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ í‰ê·  ({query_period}): {property_value_estimate:,}ë§Œì› ({len(amounts)}ê±´ ë¶„ì„)")

        # 4ï¸âƒ£ ë¦¬ìŠ¤í¬ ì—”ì§„ ì‹¤í–‰ (ê³„ì•½ íƒ€ì…ì— ë”°ë¼ ë¶„ê¸°)
        contract_type = case.get('contract_type', 'ì „ì„¸')

        # ContractData ìƒì„± (property_type, sido, sigungu í¬í•¨)
        from core.risk_engine import PropertyType, get_default_auction_rate

        # TODO: property_type, sido, sigunguë¥¼ case metadata ë˜ëŠ” ì£¼ì†Œ íŒŒì‹±ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        # ì„ì‹œë¡œ ê¸°ë³¸ê°’ ì„¤ì • (í–¥í›„ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ë°›ê±°ë‚˜ ì£¼ì†Œ íŒŒì‹±ìœ¼ë¡œ ì¶”ì¶œ)
        property_type = case.get('metadata', {}).get('property_type')  # ì˜ˆ: "ì•„íŒŒíŠ¸"
        sido = case.get('metadata', {}).get('sido')  # ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ"
        sigungu = case.get('metadata', {}).get('sigungu')  # ì˜ˆ: "ê°•ë‚¨êµ¬"
        auction_rate_override = case.get('metadata', {}).get('auction_rate_override')  # ìˆ˜ë™ ì§€ì •ê°’

        contract_data = ContractData(
            contract_type=contract_type,
            deposit=case.get('metadata', {}).get('deposit'),
            price=case.get('metadata', {}).get('price'),
            property_address=case.get('property_address') if contract_type == 'ë§¤ë§¤' else None,
            property_type=PropertyType(property_type) if property_type else None,
            sido=sido,
            sigungu=sigungu,
            auction_rate_override=auction_rate_override,
        )

        # registry_data ì—…ë°ì´íŠ¸ (ì„ëŒ€ì°¨ ê³„ì•½ì¸ ê²½ìš° ë‚™ì°°ê°€ìœ¨ ì ìš©)
        if registry_data and property_value_estimate and contract_type in ["ì „ì„¸", "ì›”ì„¸"]:
            # ë‚™ì°°ê°€ìœ¨ ê²°ì •
            auction_rate = 0.70  # ê¸°ë³¸ê°’

            if auction_rate_override is not None:
                # ìˆ˜ë™ ì§€ì •ê°’ ìš°ì„  ì‚¬ìš©
                auction_rate = auction_rate_override
                logger.info(f"ë‚™ì°°ê°€ìœ¨ (ìˆ˜ë™ ì§€ì •): {auction_rate * 100:.1f}%")
            elif property_type and sido and sigungu:
                # ìë™ ê²°ì •
                auction_rate = get_default_auction_rate(
                    property_type=PropertyType(property_type),
                    sido=sido,
                    sigungu=sigungu
                )
                logger.info(f"ë‚™ì°°ê°€ìœ¨ (ìë™ ê²°ì •): {auction_rate * 100:.1f}% (íƒ€ì…={property_type}, ì§€ì—­={sido} {sigungu})")
            else:
                logger.warning(f"ë‚™ì°°ê°€ìœ¨ ì •ë³´ ë¶€ì¡± (ê¸°ë³¸ê°’ 70% ì‚¬ìš©): property_type={property_type}, sido={sido}, sigungu={sigungu}")

            # ë¬¼ê±´ ê°€ì¹˜ ê³„ì‚°: ì‹¤ê±°ë˜ê°€ Ã— ë‚™ì°°ê°€ìœ¨
            registry_data.property_value = int(property_value_estimate * auction_rate)
            logger.info(f"ë¬¼ê±´ ê°€ì¹˜ ê³„ì‚°: {property_value_estimate}ë§Œì› Ã— {auction_rate * 100:.1f}% = {registry_data.property_value}ë§Œì›")
        elif registry_data and property_value_estimate:
            # ë§¤ë§¤ ê³„ì•½ì€ ë‚™ì°°ê°€ìœ¨ ë¯¸ì ìš©
            registry_data.property_value = property_value_estimate

        # 5ï¸âƒ£ ìƒˆ ì•„í‚¤í…ì²˜: RegistryRiskFeatures ë³€í™˜ + LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        from core.report_generator import build_risk_features_from_registry, build_llm_prompt
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import HumanMessage

        # ===========================
        # Phase 4.2: Use centralized build_analysis_context()
        # ===========================
        logger.info(f"ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘: case_id={case_id}")

        # Steps 1-6: ë°ì´í„° ìˆ˜ì§‘ ë° ì¤€ë¹„ (build_analysis_contextë¡œ ìœ„ì„)
        context = await build_analysis_context(case_id)

        # ì»¨í…ìŠ¤íŠ¸ì—ì„œ í•„ìš”í•œ ë³€ìˆ˜ ì¶”ì¶œ
        case = context.case
        registry_doc_masked = context.registry_doc_masked
        risk_result = context.risk_result
        llm_prompt = context.llm_prompt
        property_value_estimate = context.property_value_estimate
        jeonse_market_average = context.jeonse_market_average
        recent_transactions = context.recent_transactions
        contract_type = case.get('contract_type', 'ì „ì„¸')

        # MarketData ê°ì²´ ìƒì„± (ë§¤ë§¤ ê³„ì•½ ì „ìš©, ë¦¬í¬íŠ¸ ì €ì¥ìš©)
        market_data = None
        if contract_type == 'ë§¤ë§¤' and property_value_estimate:
            from core.risk_engine import MarketData
            market_data = MarketData(
                avg_trade_price=property_value_estimate,
                recent_trades=recent_transactions or [],
                avg_price_per_pyeong=None,
            )

        logger.info(f"ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ: ë“±ê¸°ë¶€={bool(context.registry_doc)}, ì‹œì¥ë°ì´í„°={bool(property_value_estimate)}")

        # Step 3: LLM í˜¸ì¶œ (í•´ì„ë§Œ ìˆ˜í–‰, íŒŒì‹±/ê³„ì‚° ì—†ìŒ)
        from core.llm_streaming import simple_llm_analysis
        final_answer = await simple_llm_analysis(llm_prompt)

        # 6ï¸âƒ£ ë¦¬í¬íŠ¸ ì €ì¥ (v2_reports í…Œì´ë¸”)
        report_data_payload = {
            "summary": final_answer,
            "risk": risk_result.risk_score.dict() if risk_result else {},
            "registry": registry_doc_masked,
            "market": market_data.dict() if (contract_type == 'ë§¤ë§¤' and market_data) else None
        }

        # ì „ì„¸/ì›”ì„¸ ê³„ì•½: ì „ì„¸ ì‹œì¥ê°€ ì •ë³´ ì¶”ê°€
        if contract_type in ["ì „ì„¸", "ì›”ì„¸"] and jeonse_market_average:
            report_data_payload["jeonse_market"] = {
                "average_deposit": jeonse_market_average,
                "period": "6ê°œì›”",
                "description": "ìµœê·¼ 6ê°œì›” ì „ì„¸ ì‹¤ê±°ë˜ê°€ í‰ê·  (100% ì‹œì¥ê°€)"
            }

        report_response = supabase.table("v2_reports").insert({
            "case_id": case_id,
            "user_id": case['user_id'],
            "content": final_answer,
            "risk_score": risk_result.risk_score.dict() if risk_result else {},
            "registry_data": registry_doc_masked,  # ë§ˆìŠ¤í‚¹ëœ ë“±ê¸°ë¶€ ì •ë³´ ì €ì¥
            "report_data": report_data_payload,
            "metadata": {
                "model": "gpt-4o-mini",
                "confidence": 0.85,
                "jeonse_market_average": jeonse_market_average if contract_type in ["ì „ì„¸", "ì›”ì„¸"] else None,
                "property_value_estimate": property_value_estimate,
            }
        }).execute()

        if not report_response.data:
            raise HTTPException(500, "Failed to save report")

        report_id = report_response.data[0]['id']
        logger.info(f"ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {report_id}")

        # 7ï¸âƒ£ ëŒ€í™” ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸ (ë¶„ì„ ë¦¬í¬íŠ¸ íƒœê¹…)
        # ì´ ì¼€ì´ìŠ¤ì™€ ì—°ê²°ëœ ëŒ€í™”ë¥¼ ì°¾ì•„ì„œ is_analysis_report=TRUE, case_id ì„¤ì •
        conversation_update = supabase.table("conversations") \
            .update({
                "is_analysis_report": True,
                "case_id": case_id,
                "updated_at": datetime.utcnow().isoformat(),
            }) \
            .eq("user_id", case['user_id']) \
            .or_(f"case_id.eq.{case_id},property_address.eq.{case['property_address']}") \
            .execute()

        if conversation_update.data:
            logger.info(f"ëŒ€í™” ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(conversation_update.data)}ê°œ ëŒ€í™” â†’ ë¶„ì„ ë¦¬í¬íŠ¸ë¡œ íƒœê¹…")
        else:
            logger.warning(f"ì—…ë°ì´íŠ¸í•  ëŒ€í™”ë¥¼ ì°¾ì§€ ëª»í•¨ (case_id={case_id}, ì£¼ì†Œ={case['property_address']})")

        # 8ï¸âƒ£ ìƒíƒœ ì „í™˜: parse_enrich â†’ report
        supabase.table("v2_cases").update({
            "current_state": "report",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", case_id).execute()

        logger.info(f"ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: case_id={case_id}, report_id={report_id}")
        return report_id

    except Exception as e:
        logger.error(f"ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}", exc_info=True)
        # ìƒíƒœë¥¼ ë‹¤ì‹œ registry_readyë¡œ ë¡¤ë°±
        supabase.table("v2_cases").update({
            "current_state": "registry_ready",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", case_id).execute()
        raise

# Reload trigger: 1763539083.3081586
